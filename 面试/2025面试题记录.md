### 面试资源

- [绘问IT面试题库](https://it.huiwenai.net/pc/group/list?id=1898270441985200129&typeId=1853061632069382145)

- [面试题](https://github.com/huiwenai/interview)

- **你看了 != 你会了 ！= 面试你能讲清楚**

# 华为

### 华为hr资格面试 2025-9-5


### 1.当前AI技术越来成熟，请你谈谈AI对程序员的影响


### 2. 对于AI技术，你是怎么看待的？

### 3. 你认为AI技术对程序员有什么影响？

A：AI技术对程序员的影响呈现出效率提升与职业重构并存的复杂态势，既带来生产力革命，也推动开发者角色向更高维度转型。以下从六个核心维度展开分析：

### 一、开发流程的智能化重构
AI工具已深度渗透编码全流程，实现从“手动编写”到“智能协作”的范式转变。以GitHub Copilot为例，其通过自然语言描述生成代码片段的能力，使基础代码编写时间缩短60%以上。阿里云通义灵码甚至能自主完成需求分析、代码生成、缺陷修复的全链路开发，5分钟即可实现传统程序员一天的工作量。这类工具不仅生成代码框架（如Flask后端路由、HTML页面结构），还能实时检测缩进错误、变量未定义等问题，并提供重构建议。

在测试环节，AI工具可自动生成覆盖3倍于传统方法的测试用例，使企业级项目测试周期缩短30%-50%。Google Gemini Code Assist更支持每月18万次代码补全，并能解释代码时间复杂度、优化异步操作逻辑，这种“编码-测试-优化”的全流程赋能，正在重塑软件开发的效率边界。

### 二、技能需求的结构性升级
程序员的能力图谱正经历三大跃迁：
1. **AI技术栈深度融合**：需掌握机器学习基础（如线性回归、神经网络）以理解AI工具原理，同时熟悉TensorFlow等框架实现模型调优。例如开发图像识别API时，需通过卷积神经网络知识调整参数优化性能。
2. **跨领域知识整合**：医疗软件开发需了解疾病诊断流程，金融AI应用需掌握风险管理知识，这种领域交叉能力成为创新关键。某金融科技企业通过AI处理重复性任务后，工程师转而专注量化模型设计，推动产品迭代效率提升40%。
3. **人机协作范式重构**：Prompt Engineering（提示工程）成为新技能，开发者需设计精准指令引导AI生成符合业务逻辑的代码。例如通过“创建用户登录界面并实现前端验证”的描述，AI可快速生成包含HTML、CSS和JavaScript的完整框架。

### 三、职业发展的两极分化
AI技术正在重塑程序员的职业坐标系：
- **传统岗位需求收缩**：初级程序员面临自动化工具和低代码平台的双重挤压，简单CRUD开发岗位减少30%。Stack Overflow调查显示，仅17%开发者“主要使用AI编写代码”，但46%表示AI处理复杂任务能力“糟糕”，这表明基础编码工作虽被替代，但复杂逻辑设计仍需人类介入。
- **新兴角色崛起**：AI系统开发工程师、算法调优师等岗位需求激增，薪资水平较普通程序员高出50%以上。某互联网企业设立“AI训练师”岗位，通过微调大模型适应量化金融场景，推动产品响应速度提升20%。
- **跨职能转型机遇**：部分开发者转向技术管理或领域专家，例如某医疗软件团队的程序员转型为AI伦理顾问，主导算法公平性审查流程。

### 四、开发者信任与效率的悖论
尽管AI工具使用率达81.4%，但信任度呈现下降趋势：46%开发者不信任AI输出，45%认为调试生成代码耗时更长。这种矛盾源于AI的“黑箱”特性——生成的代码可能存在未处理异常等漏洞，且逻辑可解释性不足。例如某电商项目因AI生成代码未考虑银联异步回调超时机制，导致支付接口故障。

效率层面同样存在“工具陷阱”：虽然AI工具使开发周期缩短70%，但Stack Overflow数据显示，开发者每天搜索答案时间仅从63%降至61%，改善幅度微弱。这表明单纯依赖工具而不优化流程，难以实现生产力质的飞跃。

### 五、行业领域的差异化冲击
不同领域受AI影响程度呈现显著差异：
- **高替代风险领域**：测试工程师（60%重复性操作）、前端开发（40%模板化工作）首当其冲。某互联网公司引入AI测试工具后，测试用例生成效率提升3倍，团队规模缩减25%。
- **中低替代风险领域**：后端开发（复杂状态管理）、算法工程师（模型可解释性需求）仍需人类主导。某金融企业在处理资金清算场景时，坚持人工设计强一致性方案，避免了AI可能引发的事务回滚风险。
- **新兴交叉领域**：量子计算与AI的融合催生新机会，例如量子机器学习可使图像识别准确率提升5%-10%，相关岗位成为稀缺资源。

### 六、应对策略与未来展望
开发者需构建“AI协作型”能力体系：
1. **技术深耕与工具驯化**：在嵌入式开发等领域建立专业壁垒，同时通过AI工具快速验证技术选型。例如某物联网团队利用AI生成硬件驱动代码后，工程师专注传感器融合算法优化，产品功耗降低15%。
2. **软技能强化**：培养需求抽象、伦理判断等不可替代能力。某教育科技企业要求程序员参与用户调研，将“沉浸式学习体验”需求转化为AI+VR应用设计，推动产品获行业创新奖。
3. **持续学习生态构建**：通过Coursera等平台学习量子计算等前沿知识，参与NeurIPS等学术会议追踪技术趋势。某开发者通过学习量子编程语言Q#，成功将AI模型训练效率提升30%。

未来，AI将从“辅助工具”进化为“协同开发者”，但人类的创造力、领域洞察和复杂决策能力仍是核心竞争力。正如蒸汽机时代工匠转向机床操作，AI时代的程序员将从代码执行者升级为技术决策者，在人机协作中定义新的价值坐标。

### 4. 你平时的学习方式


# 震雄集团

### 面试偏向业务与HR，技术比较少

#### 1. 自我介绍

#### 2. 在开发中使用的是什么系统 
- windows
- linux
- mac

#### 3. 有没有使用过工作流引擎

- Flowable
    - 流程定义（BPMN 2.0标准的XML文件）
    - 流程实例
    - 任务
    - 网关（用于控制流程的流转） 
    - 条件表达式（）
    - 边界事件
    - 流程定义
    - 集成到springboot中：POM 依赖坐标
      - flowable-spring-boot-starter 6.7.2

- Activiti

#### 4. 描述一个项目，并给出项目所使用的技术

### 5. 有没有使用过 Oracle 数据库？

# 华为OD 2025-9-8

### 一分钟自我介绍

### 问了十几个Java相关面试题

  - 线程和进程的区别？
  > 答案：进程：系统运行的基本单位，进程在运行过程中都是相互独立，但是线程之间运行可以相互影响。
    线程：独立运行的最小单位，一个进程包含多个线程且它们共享同一进程内的系统资源
    进程间通过管道、 共享内存、信号量机制、消息队列通信
  - 介绍一下常见的工厂模式？
    - 简单工厂
    - 工厂方法
    - 抽象工厂
  - 设计模式扩展
    > Spring 常用设计模式 \
    单例模式:bean默认都是单例的 \
    原型模式:指定作用域为prototype \
    工厂模式:BeanFactory \
    模板方法:postProcessBeanFactory,onRefresh,initPropertyValue \
    策略模式:XmlBeanDefinitionReader,PropertiesBeanDefinitionReader \
    观察者模式:listener,event,multicast \
    适配器模式:Adapter \
    装饰者模式:BeanWrapper \
    责任链模式:使用aop的时候会先生成一个拦截器链 \
    代理模式:动态代理
  - spring cloud 常见的组件？
    - 服务注册用发现
      - Nacos(功能全面)
      - Consul(强一致性)
    - 服务调用组件
      - OpenFeign + Spring Cloud LoadBalancer
    - 网关
      - spring cloud gateway
    - 容错与流量配置
      - Sentinel（高并发）或 Resilience4J（轻量）
    - 配置管理
      - Nacos Config
    - 负载均衡与服务调用
      - OpenFeign + Spring Cloud LoadBalancer
    - 分布式追踪
      - Micrometer Tracing + Zipkin
    - 消息驱动
    - 安全认证
      - Spring Cloud Security + OAuth2/JWT  
    - 分布式事务
      - Seata
        -  AT模式 保证常见关系型数据库分布式事务的一致性
          - AT模式是一种无侵入式的分布式事务模式（本地事务+补偿机制），使用与关系型数据库如（MySql）,核心依赖（undo log）回滚日志和全局锁保持一致（XID）全局事务ID
        - TCC模式 保证常见关系型数据库分布式事务的一致性
        - SAGA模式 保证常见关系型数据库分布式事务的一致性

# 金蝶 2025-9-9

### Spring Cloud 问的很多？
    
- Spring Cloud 常用组件？

    - 服务注册与发现 （open feign (alibaba)   ）

- Spring Cloud 服务间调用使用的是什么组件？
  - open feign + spring cloud load balancer

- 服务间调用如何保证数据安全？
  - ：
  - 
# 消息队列问的很深

## 为什么选择kafka?

Kafka是目前业界广泛应用的分布式消息流平台，被广泛选用的原因主要在于其高性能、分布式架构、对多种数据处理的支持以及高可扩展性等优势。具体如下：
- **高性能持久化**：Kafka能够以常数时间复杂度（O(1)）访问存储中的数据，即使面对TB级甚至PB级别的数据量，也能保证访问性能不随数据增长而退化。每条消息根据offset定位，直接进行文件seek操作，无需全量扫描或索引搜索。消息保存在顺序写入的日志文件中，读取时直接从磁盘按偏移量访问，效率极高。
- **极高的吞吐率**：Kafka在同等硬件条件下，比传统消息队列拥有更高的性能表现，单机每秒可实现10万条以上的消息处理能力。这得益于其顺序写磁盘（比随机写内存更快、更稳定）、高Page Cache利用率、批量发送写入机制以及零拷贝技术（减少数据在内核与用户态之间的复制次数）等。
- **强大的分布式能力与数据顺序保证**：Kafka原生支持水平扩展的分布式架构。同一个Topic可以拆分为多个Partition，分布在多个Kafka Broker上，每个Partition可独立扩展，提高整体处理能力。多个消费者组成Consumer Group，可自动分配消费任务，实现高并发处理。虽然多个Partition并行处理，但每个Partition中消息严格按照发送顺序排列和读取。
- **支持实时与离线数据处理**：Kafka可同时对接实时数据处理系统，如Flink、Spark Streaming等，用于秒级延迟的数据分析与反应；也可对接离线处理系统，如Hadoop、Hive等，作为数据管道的缓冲层，将原始日志或传感器数据写入HDFS或对象存储，是构建统一数据管道平台的基础设施。
- **高可扩展性与易运维性**：Kafka支持在不中断服务的前提下实现集群容量提升。可通过增加Broker实例，扩展Topic的Partition，实现读写能力的线性增长。每个Broker可绑定不同磁盘，利用多磁盘并行存储，提高单节点处理性能。还可动态添加Zookeeper节点以增强元数据管理和集群协调能力。此外，每个Partition可配置多个副本，实现主从故障切换和数据可靠性保障。

## - 请说一下rabbitMQ 中 vhost 的作用？

  >  RabbitMQ 中的 **Virtual Host**（虚拟主机，简称 vhost）是一个非常重要的逻辑隔离机制。你可以把它想象成一台物理服务器（RabbitMQ Broker）里的多个独立「迷你消息服务器」，每个都有自己全套的资源（交换机、队列、绑定关系）和权限体系。

| 作用与场景         | 说明                                                                 | 举例                                     |
| :----------------- | :------------------------------------------------------------------- | :--------------------------------------- |
| **资源隔离**       | 不同vhost间的交换机、队列、消息绝对隔离，无法直接通信。            | `/app1` 的订单队列无法被 `/app2` 消费        |
| **权限控制**       | 用户权限基于vhost分配，实现安全管控。                       | 用户A可管理`/prod`，但只能读`/test`         |
| **多环境支持**     | 同一集群上为不同环境（开发、测试、生产）创建独立的vhost。                 | `/dev`, `/test`, `/prod`                 |
| **多租户架构**     | SaaS应用中，为不同客户分配独立vhost，实现数据隔离。                      | `/tenant_alibaba`, `/tenant_tencent`     |
| **命名空间**       | 资源（如队列名）只需在所属vhost内唯一，不同vhost可重名。 | `/app1/logs` 和 `/app2/logs` 可以共存且互不影响 |

默认情况下，RabbitMQ 自带一个名为 `/` 的 vhost。**强烈建议在生产环境中创建并使用新的 vhost**，而不是继续使用这个默认的 vhost，以避免潜在混淆。

### 🔧 管理 Vhost

管理 vhost 的常用方式有以下几种：

1.  **命令行工具 (`rabbitmqctl`)**: 最直接的方式，适合脚本化和服务器管理。
    ```bash
    # 创建 vhost
    rabbitmqctl add_vhost /your_vhost_name
    # 删除 vhost
    rabbitmqctl delete_vhost /your_vhost_name
    # 列出所有 vhost
    rabbitmqctl list_vhosts
    ```
    创建后通常需为用户授权：
    ```bash
    # 授予用户 alice 对 vhost /your_vhost_name 的所有操作权限
    rabbitmqctl set_permissions -p /your_vhost_name alice ".*" ".*" ".*"
    ```


2.  **Web 管理界面**: 通过浏览器访问 RabbitMQ 的 Web 管理界面（默认端口 `15672`），在 **Admin** -> **Virtual Hosts** 标签页中，可以直观地创建、删除 vhost 以及管理其权限。

3.  **HTTP API**: 通过调用 RabbitMQ 提供的 HTTP API 管理 vhost，便于自动化集成。

### 📌 客户端连接指定 Vhost

生产者和消费者在连接 RabbitMQ 时，**必须指定要使用的 vhost**（如果使用默认的 `/`，有时客户端库可能允许省略，但显式指定是好习惯）。

以下是不同语言的连接示例：

-   **Java (使用 amqp-client)**:
    ```java
    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");
    factory.setVirtualHost("/your_vhost_name"); // 指定 vhost
    factory.setUsername("your_username");
    factory.setPassword("your_password");
    Connection connection = factory.newConnection();
    ```



### 💡 最佳实践与注意事项

*   **清晰的命名**：为vhost起一个有意义的名字，如按项目`/project-x`、按环境`/prod`、按团队`/team-data`。
*   **权限最小化原则**：遵循**最小权限原则**，只授予用户必要的权限。
*   **区分环境**：为开发、测试、生产等不同环境创建不同的vhost，并确保应用程序连接配置正确，避免误操作。
*   **监控与清理**：定期监控各个vhost的资源使用情况（连接数、队列数、消息速率等），并清理不再使用的vhost。

### ⚠️ 需要注意的要点

-   **vhost 不直接存储消息**：消息存储在队列中，而队列属于特定的 vhost。
-   **连接必须指定 vhost**：客户端连接时必须指定一个已存在且有权限的 vhost，否则连接会失败。
-   **默认 vhost 的风险**：生产环境中建议避免使用默认的 `/` vhost，并为不同应用或环境创建独立的 vhost，**严禁不同环境共用同一 vhost**。
-   **权限是关键**：vhost的隔离安全性严重依赖于正确的用户和权限设置。

- rabbit mq 与kefka 对比优劣势？

- kafka 消费端如何保证数据一致性？
    - 1.ISR（同步副本集）：每个分区维护一个与 Leader 同步的副本列表，只有 ISR 中的副本才被视为有效备份。当生产者设置 acks=all 时，消息需被所有 ISR 副本写入后才确认成功，确保数据不丢失
    - 2.幂等性处理
    - 3.原子提交：通过 Kafka 事务将消息处理与偏移量提交绑定，确保二者要么同时成功，要么回滚。
    - 4.kafka 默认是异步提交，异步提交会丢失数据； 
    - 同步提交：在消息处理完成后调用 **consumer.commitSync()**，确保偏移量提交成功。适合对一致性要求高的场景


# 数据库

## MySQL一张数据量很大的表如何优化查询速度？

### 核心思路
优化的核心思路可以归纳为以下几点：
1.  **减少数据量**：让数据库引擎需要扫描和计算的数据尽可能的少。
2.  **减少计算量**：优化查询逻辑，避免复杂的计算和临时表。
3.  **转换思路**：用空间换时间，通过增加硬件资源或冗余数据来提升速度。
4.  **终极方案**：当单表优化到极限时，必须进行架构上的拆分。

---

### 一、 基础且高效的优化（首选方案）

这些方法成本低、见效快，应优先考虑。

#### 1. 优化索引 (Index Optimization)
索引是优化查询最直接有效的手段。

*   **确保查询使用了合适的索引**： 使用 `EXPLAIN` 命令分析你的慢查询，查看是否使用了索引，以及使用的是哪个索引。
    ```sql
    EXPLAIN SELECT * FROM your_large_table WHERE some_column = 'value';
    ```
    关注 `key`（使用的索引）、`rows`（预估扫描行数）、`type`（访问类型，`const`, `ref`, `range` 为佳，`ALL` 为全表扫描需避免）。

*   **为 `WHERE`, `JOIN`, `ORDER BY`, `GROUP BY` 子句中的列创建索引**。

*   **避免冗余和未使用的索引**： 索引会降低写操作（INSERT/UPDATE/DELETE）的速度并占用空间。定期检查并删除未使用的索引。

*   **使用覆盖索引 (Covering Index)**： 如果索引包含了查询所需要的所有字段，MySQL就可以直接从索引中获取数据，而不需要回表查询数据行，效率极高。
    *   **坏**：`SELECT * FROM table WHERE indexed_column = 'value’;` (需要回表)
    *   **好**：`SELECT indexed_column, other_indexed_column FROM table WHERE indexed_column = 'value’;` (可能覆盖索引)

*   **注意索引的选择性**： 为选择性高的列创建索引效果更好（例如，身份证号、用户名）。选择性低的列（如：性别、状态标志）加索引效果不大，有时反而更差。

*   **前缀索引 (Prefix Indexes)**： 对于 TEXT/BLOB 或很长的 VARCHAR 列，可以只对列的前 N 个字符创建索引，节省空间。
    ```sql
    CREATE INDEX idx_name ON your_table (long_column_name(255));
    ```

#### 2. 优化SQL查询语句 (Query Optimization)
很多时候，慢查询是因为SQL写得不好。

*   **只获取需要的列**： 坚决避免 `SELECT *`，尤其是表中有TEXT/BLOB等大字段时。明确指定需要的列。
*   **使用高效的查询条件**：
    *   避免在 WHERE 子句中对字段进行函数操作（如 `WHERE YEAR(create_time) = 2023`），这会导致索引失效。应改为范围查询（`WHERE create_time BETWEEN '2023-01-01' AND '2023-12-31'`）。
    *   小心使用 `OR`，可能导致全表扫描。可以考虑用 `UNION` 替代。
    *   避免使用 `!=` 或 `NOT IN`，它们通常无法使用索引。
*   **优化联表查询 (JOIN)**：
    *   确保 `ON` 或 `USING` 子句中的列上有索引。
    *   被驱动表（第二个表）的连接列必须有索引。
    *   小表驱动大表。

---

### 二、 中级优化（表结构和系统层面）

当基础优化做到极致后，可以考虑这些方案。

#### 1. 分区表 (Partitioning)
将一张大表在物理上分割成多个更小的、更易管理的部分（分区），但对应用来说仍然是一张逻辑表。

*   **适用场景**： 数据有明显的逻辑区间，比如按时间（年/月）、地域范围等。常用于日志表、历史订单表。
*   **优点**： 查询时，优化器可以自动只扫描所需的分区（**分区裁剪**），极大减少扫描数据量。
*   **缺点**： 对业务透明，但管理复杂，且有很多限制（如所有分区必须使用相同的存储引擎、主键/唯一索引必须包含分区键）。
*   **示例**：
    ```sql
    CREATE TABLE sales (
        id INT NOT NULL,
        purchase_date DATE NOT NULL
    )
    PARTITION BY RANGE(YEAR(purchase_date)) (
        PARTITION p0 VALUES LESS THAN (1990),
        PARTITION p1 VALUES LESS THAN (2000),
        PARTITION p2 VALUES LESS THAN (2010),
        PARTITION p3 VALUES LESS THAN (2020),
        PARTITION p4 VALUES LESS THAN MAXVALUE
    );
    -- 查询2023年的数据，只会扫描2023年所在的分区
    SELECT * FROM sales WHERE purchase_date BETWEEN '2023-01-01' AND '2023-12-31';
    ```

#### 2. 使用更快的存储设备
**将数据库放在SSD硬盘上**。IO瓶颈往往是数据库性能的最大杀手，SSD的随机读写能力远超机械硬盘，能极大提升查询和更新速度。

#### 3. 调整服务器参数 (Configuration Tuning)
优化MySQL的配置参数（`my.cnf` / `my.ini`），这对性能提升也很关键。

*   **`innodb_buffer_pool_size`**： **这是最重要的参数**。InnoDB缓冲池用于缓存表数据和索引。建议设置为可用物理内存的 **70%-80%**。让热数据尽可能留在内存中。
*   **`innodb_buffer_pool_instances`**： 如果缓冲池很大（比如 > 16GB），可以设置多个实例来减少锁竞争。
*   **`max_connections`**： 合理设置最大连接数，避免过多连接耗尽资源。
*   **`query_cache_size`**： **注意：在MySQL 5.7.20开始已弃用，8.0中已移除**。如果你的版本较早，可以考虑是否启用查询缓存，但对于写频繁的应用，查询缓存可能弊大于利。

**警告**： 不要盲目修改参数，最好参考官方文档或使用像 `MySQLTuner` 这样的工具来分析当前配置。

---

### 三、 高级/架构优化（应对海量数据）

当单表优化到极限，数据量持续增长时，必须从架构上动刀。

#### 1. 读写分离 (Read/Write Splitting)
*   **主从复制 (Master-Slave Replication)**： 搭建一个主库（Master）负责处理写操作（INSERT/UPDATE/DELETE），多个从库（Slave）通过复制同步主库的数据，负责处理读操作（SELECT）。
*   **优点**： 分摊数据库压力，提升读性能。从库还可以用于备份和数据分析，不影响主库。
*   **缺点**： 存在主从同步延迟，对数据一致性要求非常高的读操作可能需要读主库。

#### 2. 垂直拆分 (Vertical Sharding)
*   **做法**： 将一个包含很多字段的大表，按访问频度拆分成多个小表（例如，将常用的主字段放在一个表，将不常用的大字段如`TEXT`、`BLOB`放到另一个扩展表）。
*   **优点**： 使得核心查询需要扫描的数据页更少，IO效率更高。
*   **缺点**： 应用层需要做相应修改，查询时需要联表。

#### 3. 水平拆分/分库分表 (Horizontal Sharding)
这是处理亿级以上数据的终极大招。

*   **做法**： 将一张表的数据**按某种规则（分片键）** 分散到多个数据库或多个数据表中。例如，按用户ID哈希取模，或按时间范围。
*   **优点**： 从根本上解决了单表、单库的性能瓶颈和容量上限问题。
*   **缺点**：
    *   **复杂度极高**： 应用层需要大幅修改，需要中间件（如 ShardingSphere, MyCat, Vitess）来管理分片路由。
    *   跨分片查询、聚合、排序、事务变得非常复杂和困难。
    *   扩容（如增加分片数量）操作繁琐。

**常见的分片策略**：
*   **范围分片**： 按时间或ID范围（如1-100万在表1，100万-200万在表2）。容易产生热点数据。
*   **哈希分片**： 对分片键（如`user_id`）进行哈希取模，均匀分布数据。扩容时数据迁移量大。
*   **地理位置分片**： 根据用户地域分到不同的数据库。

---

### 总结与操作流程

当你面对一张大表时，建议按以下步骤进行排查和优化：

1.  **定位问题**： 使用**慢查询日志 (Slow Query Log)** 找出最耗时的SQL。
2.  **分析SQL**： 对慢SQL使用 **`EXPLAIN`** 命令，分析其执行计划，看是否索引失效、是否全表扫描。
3.  **优化索引**： 根据 `EXPLAIN` 的结果，添加或调整索引。这是最快的方法。
4.  **优化SQL**： 重写SQL，避免 `SELECT *`，避免在WHERE子句中使用函数等。
5.  **考虑分区**： 如果数据有明显的冷热特性（如时间），考虑使用分区表。
6.  **调整配置**： 优化 `innodb_buffer_pool_size` 等核心参数。
7.  **硬件升级**： 使用SSD硬盘，增加内存。
8.  **架构升级**： 如果以上所有方法都无法满足需求，再考虑**读写分离**和**分库分表**这些重量级方案。


## NOSQL

- 你们经常用的NoSQL数据库有哪些？

## 运维Linux相关
 - docker file 会写吗？
 - 常见Linux命令
 - Spring boot jar包 启动命令行
 - 服务报警你们是如何做的，如何处理？

### 前端 
- vue 生命周期函数有哪些？
> 1. 创建阶段
     beforeCreate（选项式 API）
     触发时机：组件实例初始化后，数据观测和事件配置前。
     用途：初始化非响应式数据或全局配置（如第三方库初始化）。
     组合式 API 替代：逻辑直接写在 setup 函数中。
     created（选项式 API）
     触发时机：实例创建完成，数据观测和事件初始化后。
     用途：访问组件数据、发送异步请求（如获取初始数据）。
     组合式 API 替代：逻辑直接写在 setup 函数中。
>2. 挂载阶段
   beforeMount（选项式 API）
   触发时机：模板编译完成，但未挂载到真实 DOM。
   用途：修改虚拟 DOM 或初始化非 DOM 资源。
   组合式 API：onBeforeMount（需从 vue 导入）。
   mounted（选项式 API）
   触发时机：组件挂载到 DOM 后，可安全访问真实 DOM。
   用途：操作 DOM（如初始化图表库）、发送依赖 DOM 的异步请求。
   组合式 API：onMounted（示例见下方代码）。
>3. 更新阶段
   beforeUpdate（选项式 API）
   触发时机：响应式数据变化，虚拟 DOM 重新渲染前。
   用途：获取更新前的状态（如滚动位置），避免在此阶段修改数据。
   组合式 API：onBeforeUpdate。
   updated（选项式 API）
   触发时机：数据和 DOM 更新完成后。
   用途：依赖最新 DOM 状态的操作（如调整布局），避免在此修改数据导致循环更新。
   组合式 API：onUpdated。
>4. 卸载阶段
   beforeUnmount（选项式 API，替代 Vue 2 的 beforeDestroy）
   触发时机：组件卸载前，DOM 仍存在。
   用途：清理定时器、解绑事件监听、取消网络请求等资源释放操作。
   组合式 API：onBeforeUnmount。
   unmounted（选项式 API，替代 Vue 2 的 destroyed）
   触发时机：组件卸载后，所有指令和事件监听器已解绑。
   用途：执行最终清理（如日志记录），此时无法访问组件实例。
   组合式 API：onUnmounted。

# vivo 外包 2025-9-9

## 离职原因

## 平常如何学习的？

## 数据库相关

## 说一下SQL执行流程

## 了解MySQL索引吗？说一下B+索引，叶子节点存放了几条数据？

## 你知不知道MVCC特性？

## 你在华为有没有遇到慢SQL，是如何优化的？

# Java核心

## jvm 如何计算实例对象占用内存的？

## new一个对象，对象的运行流程？

## redis

## 有没有用到redis，你们都是用在什么场景？

- 缓存
- 分布式锁

## redis String 内部是如何实现的？

Redis中String类型底层主要通过整数和简单动态字符串（SDS）实现，根据存储值的类型和长度不同，其内部编码方式分为int、raw和embstr三种。具体如下：
- **int编码**：如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面（将void*转换成long），并将字符串对象的编码设置为int。这样在对整数进行增减（如INCR或DECR操作）时，性能更好，无需将字符串转换为整数。
- **raw编码**：如果字符串对象保存的是一个字符串，并且这个字符串的长度大于32字节（Redis 2.+版本），那么字符串对象将使用SDS来保存这个字符串，并将对象的编码设置为raw。raw编码会通过调用两次内存分配函数，分别分配两块空间来保存redisObject和SDS，以方便对较长字符串进行修改操作。
- **embstr编码**：如果字符串对象保存的是一个字符串，并且这个字符串的长度小于等于32字节（Redis 2.+版本），那么字符串对象将使用SDS来保存这个字符串，并将对象的编码设置为embstr。embstr编码是专门用于保存短字符串的一种优化编码方式，它通过一次内存分配函数分配一块连续的内存空间，来保存redisObject和SDS，这样不仅减少了内存分配次数，还能更好地利用CPU缓存提升性能。

# Mysql 读写分离如何保证事务的一致性?

这是一个非常经典且重要的问题。数据库读写分离在提升系统性能的同时，也确实引入了数据一致性的挑战。首先，我们需要清晰地理解问题的根源。

### 为什么读写分离会导致数据不一致？

根本原因在于**主从复制是异步的**。
1.  一个写请求（增、删、改）在主库上完成。
2.  主库将此次变更写入**二进制日志（binlog）**。
3.  从库的**I/O线程**异步地拉取主库的binlog。
4.  从库的**SQL线程**异步地重放（replay）这些binlog，从而应用更改。

步骤3和4的异步性导致了**复制延迟（Replication Lag）**，即从库的数据落后于主库。因此，用户在写入后立刻去从库查询，可能会查不到刚写入的数据，或者读到旧数据。

---

保证数据一致性没有“银弹”，需要根据业务场景在**一致性强度**和**系统性能**之间做出权衡。以下是几种常见的解决方案，从强一致性到弱一致性排列。

### 一、强一致性方案（牺牲部分性能，保证绝对一致）

这类方案要求读操作也走主库，完全规避复制延迟。

1.  **强制读主（Master Read）**
    *   **做法**：所有对数据一致性要求高的读请求（如“读写后立刻查询”、“查询账户余额”）都不经过从库，直接发往主库。
    *   **优点**：实现简单，绝对保证强一致性。
    *   **缺点**：完全丧失了读写分离带来的读性能提升，主库压力大。通常只用于关键业务。

2.  **分布式事务/强一致性协议**
    *   **做法**：使用如Paxos、Raft等分布式共识算法，确保数据在写入主库的同时，必须在多数从库上也同步完成才算成功。或者使用MySQL Group Replication等强一致性集群方案。
    *   **优点**：真正实现了数据库层面的强一致性。
    *   **缺点**：性能开销极大，写入延迟非常高，实现和运维复杂。通常用于金融核心等对一致性有极端要求的场景，一般不作为读写分离的常规解决方案。

### 二、最终一致性方案（保证性能，接受短暂不一致）

这是最常用的思路，系统承认存在短暂的不一致，但通过一些技巧让用户尽可能感知不到，或快速变为一致。

1.  **半同步复制（Semi-Synchronous Replication）**
    *   **做法**：在主库执行完一个事务后，**至少等待一个从库接收并确认**（不一定要重放完成）binlog后，才返回成功给客户端。
    *   **优点**：相比异步复制，显著降低了数据丢失的风险（主库宕机时，至少有一个从库有最新数据），也缩短了复制延迟窗口。
    *   **缺点**：比异步复制性能稍差，因为多了一次网络往返的耗时。如果从库一直不确认，超时后会自动降级为异步复制。

2.  **中间件/代理层判断**
    *   **做法**：在数据库中间件（如ShardingSphere、ProxySQL）或应用层进行路由判断。
        *   **写后读主**：在同一个会话（Session/Connection）中，如果执行了写操作，在此会话后续的一定时间窗口内（如500ms）的所有读请求都自动路由到主库。可以通过在中间件中设置一个`last_write_time`的标记来实现。
        *   **基于Hint的路由**：对于特定必须读主的请求，通过在SQL注释中加入特殊标记（如 `/* master */ SELECT ...`），让中间件识别并将其路由到主库。

3.  **数据库外部缓存**
    *   **做法**：写操作不仅更新数据库，同时更新Redis等高速缓存。读操作优先查询缓存。
    *   **优点**：性能极高，既能分担数据库读压力，又能保证读到最新数据。
    *   **缺点**：系统复杂度升高，需要维护缓存和数据库之间的数据一致性（缓存过期、穿透、击穿、雪崩等问题）。

4.  **关键业务查询走主库**
    *   **做法**：这是对“强制读主”的细化。不是所有读都走主库，而是根据业务逻辑区分。
        *   **读用户自己的信息**：用户刚更新了个人信息，后续立刻查看，这类请求走主库。
        *   **读别人的信息/非关键数据**：浏览新闻列表、查看他人主页等，这类请求走从库。
    *   **优点**：在性能和一致性之间取得了很好的平衡，是实践中非常常用的模式。

### 三、应对方案总结与选型建议

| 方案 | 一致性强度 | 性能影响 | 实现复杂度 | 适用场景 |
| :--- | :--- | :--- | :--- | :--- |
| **强制读主** | **强一致** | 高（主库压力大） | 低 | 核心业务，如支付、余额查询 |
| **分布式协议** | **强一致** | 非常高（写入延迟高） | 极高 | 金融核心交易，不计成本保证一致 |
| **半同步复制** | **最终一致**（但延迟极短） | 中（比异步复制差） | 中 | 通用方案，平衡数据安全与性能 |
| **写后读主/中间件** | **最终一致**（会话内强一致） | 低 | 中 | 最推荐的通用方案，用户体验好 |
| **外部缓存** | **最终一致**（缓存有效期） | 极高（读缓存快） | 高 | 读多写少，对响应速度要求极高 |
| **业务区分读写** | **最终一致** | 低 | 中 | 需要业务代码配合，通用性强 |

### 实践中的组合策略

在实际生产环境中，通常会**组合使用**多种方案，而不是单一选择：

1.  **基础架构**：采用**半同步复制**作为数据库底层保障，确保数据不会丢失且延迟较低。
2.  **架构设计**：引入**中间件**，并默认开启**写后读主**策略，保证用户在同一会话内感知不到延迟。
3.  **业务开发**：在业务代码中，对**关键业务逻辑**（如订单创建后的查询）显式指定`/* master */` hint，强制走主库。
4.  **性能加速**：对**热点数据**（如商品详情）使用**Redis缓存**，进一步提升读性能并降低数据库压力。

**结论：**
保证读写分离下的数据一致性，核心思路是 **“根据业务场景分级处理”** 。大部分场景接受最终一致性，通过**写后读主、业务区分**等技巧来提升用户体验；小部分核心场景则通过**强制读主**来保证强一致性。没有完美的方案，只有最适合业务现状的权衡。


## 卓望 9-12

## SpringCloud服务调用组件OpenFeign如何增加请求头？

在 Spring Cloud OpenFeign 中添加请求头，核心是根据 **请求头的作用范围（局部/全局）** 和 **动态性需求** 选择不同方案。以下是具体代码实现和详细说明，覆盖所有常用场景：


## 一、局部请求头（仅作用于单个 Feign 方法/接口）
局部请求头适用于“特定接口需要专属请求头”的场景，比如某个接口需要单独的 `App-Secret` 或 `Content-Type`。

### 1. 方案1：通过 `@RequestMapping` 系列注解的 `headers` 属性
直接在 `@GetMapping`/`@PostMapping` 等注解中通过 `headers` 属性硬编码或引用配置文件中的请求头。

#### 步骤1：配置文件（可选，用于动态值）
若请求头值需要动态配置（如从 `application.yml` 读取），先定义配置：
```yaml
# application.yml
feign:
  headers:
    app-secret: "dev_123456"  # 动态配置的请求头值
    content-type: "application/json;charset=UTF-8"
```

#### 步骤2：Feign 接口代码
```java
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;

// 声明 Feign 客户端（name 为服务名，url 可用于本地调试）
@FeignClient(name = "user-service", url = "${feign.url.user-service:http://localhost:8081}")
public interface UserFeignClient {

    // 方式1：直接硬编码请求头
    @PostMapping(value = "/api/user/save", headers = "Content-Type=application/json;charset=UTF-8")
    Boolean saveUserHardCode(@RequestBody UserDTO userDTO);

    // 方式2：引用配置文件中的请求头（推荐，支持动态修改）
    @PostMapping(
        value = "/api/user/query",
        headers = {
            "Content-Type=${feign.headers.content-type}",  // 引用配置的 Content-Type
            "App-Secret=${feign.headers.app-secret}"       // 引用配置的 App-Secret
        }
    )
    UserVO queryUserBySecret(@RequestBody UserQueryDTO queryDTO);
}
```


### 2. 方案2：通过 `@RequestHeader` 注解（支持动态参数）
若请求头值需要从调用方传入（如动态的 `Authorization` Token），使用 `@RequestHeader` 注解绑定参数。

#### Feign 接口代码
```java
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestHeader;
import org.springframework.web.bind.annotation.RequestParam;

@FeignClient(name = "order-service")
public interface OrderFeignClient {

    // 场景1：单个动态请求头（如 Authorization Token）
    @GetMapping("/api/order/detail")
    OrderVO getOrderDetail(
        @RequestParam("orderId") Long orderId,
        // 从调用方传入 Token，绑定到 Authorization 请求头
        @RequestHeader("Authorization") String token
    );

    // 场景2：多个动态请求头（用 MultiValueMap 接收，支持一个 key 对应多个 value）
    @GetMapping("/api/order/list")
    PageInfo<OrderVO> getOrderList(
        @RequestParam("userId") Long userId,
        // 接收多个请求头（如 Authorization、User-Region）
        @RequestHeader MultiValueMap<String, String> dynamicHeaders
    );
}
```

#### 调用方代码（Controller 层示例）
```java
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.util.LinkedMultiValueMap;
import org.springframework.util.MultiValueMap;

@RestController
public class OrderController {

    private final OrderFeignClient orderFeignClient;

    // 构造注入 Feign 客户端
    public OrderController(OrderFeignClient orderFeignClient) {
        this.orderFeignClient = orderFeignClient;
    }

    // 调用场景1：传入单个 Token
    @GetMapping("/order/detail")
    public OrderVO getOrderDetail(@RequestParam("orderId") Long orderId) {
        String userToken = "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."; // 从 Session/Redis 中获取
        return orderFeignClient.getOrderDetail(orderId, userToken);
    }

    // 调用场景2：传入多个动态请求头
    @GetMapping("/order/list")
    public PageInfo<OrderVO> getOrderList(@RequestParam("userId") Long userId) {
        MultiValueMap<String, String> headers = new LinkedMultiValueMap<>();
        headers.add("Authorization", "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...");
        headers.add("User-Region", "Shanghai"); // 额外的请求头
        headers.add("Accept-Language", "zh-CN");
        return orderFeignClient.getOrderList(userId, headers);
    }
}
```


### 3. 方案3：通过 `@Headers` 注解（Feign 原生注解）
`@Headers` 是 Feign 原生注解，可作用于类（所有方法生效）或方法（单个方法生效），但需注意：
- 若使用 `@Headers`，需配置 Feign 原生契约（默认是 SpringMVC 契约，不识别 `@Headers`）。

#### 步骤1：配置 Feign 原生契约
```java
import feign.Contract;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

// Feign 配置类（注意：若加 @Configuration，需避免被 Spring 扫描到全局生效，建议放在非主包下）
public class FeignNativeConfig {

    // 配置 Feign 原生契约（支持 @Headers、@RequestLine 等原生注解）
    @Bean
    public Contract feignContract() {
        return new Contract.Default();
    }
}
```

#### 步骤2：Feign 接口代码（使用原生注解）
```java
import feign.Headers;
import feign.Param;
import feign.RequestLine;
import org.springframework.cloud.openfeign.FeignClient;

// 指定配置类，启用原生契约
@FeignClient(name = "product-service", configuration = FeignNativeConfig.class)
@Headers("Content-Type: application/json;charset=UTF-8") // 类级别：所有方法都带此请求头
public interface ProductFeignClient {

    // 方法级别：额外添加 Authorization 请求头（支持动态参数，用 {token} 占位）
    @RequestLine("GET /api/product/{productId}") // 原生请求方式+路径
    @Headers("Authorization: {token}")
    ProductVO getProductById(
        @Param("productId") Long productId, // 路径参数，对应 {productId}
        @Param("token") String token        // 请求头参数，对应 {token}
    );
}
```


## 二、全局请求头（作用于所有 Feign 接口/指定 Feign 客户端）
全局请求头适用于“所有接口都需要统一携带的请求头”，比如 `Token`、`App-Id`、`User-Agent` 等，无需在每个方法中重复定义。

核心是实现 Feign 提供的 `RequestInterceptor` 接口，通过拦截器统一添加请求头。


### 1. 方案1：全局生效（所有 Feign 客户端）
配置一个全局的 `RequestInterceptor`，所有 Feign 调用都会携带该请求头。

#### 代码实现
```java
import feign.RequestInterceptor;
import feign.RequestTemplate;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;

import javax.servlet.http.HttpServletRequest;

// 全局 Feign 配置（加 @Configuration 后，会被所有 Feign 客户端继承）
@Configuration
public class GlobalFeignConfig {

    @Bean
    public RequestInterceptor globalRequestInterceptor() {
        return new RequestInterceptor() {
            @Override
            public void apply(RequestTemplate template) {
                // 1. 添加固定请求头（所有请求都携带）
                template.header("App-Id", "feign-demo-1.0");
                template.header("User-Agent", "SpringCloud-OpenFeign");

                // 2. 添加动态请求头（如从当前请求中获取 Token，传递给下游服务）
                // 注意：若 Feign 调用是异步的（如 @Async），RequestContextHolder 可能获取不到请求，需特殊处理
                ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
                if (attributes != null) {
                    HttpServletRequest request = attributes.getRequest();
                    // 从当前请求的 Header 中获取 Authorization，传递给 Feign 调用
                    String token = request.getHeader("Authorization");
                    if (token != null && !token.isEmpty()) {
                        template.header("Authorization", token);
                    }
                }
            }
        };
    }
}
```


### 2. 方案2：指定 Feign 客户端生效（局部全局）
若只需某个 Feign 客户端携带全局请求头，无需影响其他客户端，可在 `@FeignClient` 的 `configuration` 属性中指定专属配置类。

#### 步骤1：专属 Feign 配置类（无 @Configuration 注解，避免全局生效）
```java
import feign.RequestInterceptor;
import feign.RequestTemplate;
import org.springframework.context.annotation.Bean;

// 专属配置类（不加 @Configuration，仅在指定 Feign 客户端中生效）
public class PaymentFeignConfig {

    @Bean
    public RequestInterceptor paymentRequestInterceptor() {
        return template -> {
            // 仅 PaymentFeignClient 会携带这些请求头
            template.header("Payment-App-Key", "payment_789");
            template.header("Encrypt-Type", "AES");
        };
    }
}
```

#### 步骤2：Feign 接口指定配置类
```java
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;

// 仅当前 Feign 客户端使用 PaymentFeignConfig，携带专属全局请求头
@FeignClient(name = "payment-service", configuration = PaymentFeignConfig.class)
public interface PaymentFeignClient {

    @PostMapping("/api/payment/create")
    Boolean createPayment(@RequestParam("orderId") Long orderId);
}
```


## 三、关键注意事项
1. **异步调用的请求头传递问题**  
   若 Feign 调用在 `@Async` 异步方法中执行，`RequestContextHolder` 会丢失当前 HTTP 请求上下文，导致无法获取 `Authorization` 等动态头。  
   解决方案：手动传递请求头参数，或使用 `ThreadLocal` 存储上下文。

2. **请求头重复问题**  
   若多个方案同时添加同一请求头（如全局拦截器和 `@RequestHeader`），Feign 会保留所有值（多个相同 Key 的请求头），而非覆盖。若需避免重复，需在代码中判断是否已存在该请求头。

3. **Feign 契约冲突**  
   使用 `@Headers` 等原生注解时，必须配置 `Contract.Default()`，否则注解不生效；而配置原生契约后，`@GetMapping`/`@PostMapping` 等 SpringMVC 注解会失效，需二选一。


通过以上方案，可覆盖 OpenFeign 中所有添加请求头的场景，根据实际需求选择局部或全局方案即可。

## Spring Cloud Config 修改配置能够实时刷新吗？

Spring Cloud Config修改配置能够实时刷新。它提供了手动刷新和自动刷新两种机制来实现配置的实时刷新，以确保服务能够实时获取最新的配置信息。具体如下：
- **手动刷新**：
    - **添加依赖**：在Config Client的`pom.xml`中引入`spring-boot-starter-actuator`依赖，该依赖提供了刷新端点。
    - **配置暴露端点**：在Config Client的配置文件中，设置`management.endpoints.web.exposure.include=*`，以暴露所有的Actuator端点，包括用于刷新配置的`/refresh`端点。
    - **标记Bean**：使用`@RefreshScope`注解标记需要动态刷新的Bean。当配置更新并触发刷新端点后，这些Bean将重新初始化，并应用新的配置值。
    - **触发刷新**：通过工具如Postman或curl命令，向Config Client的`/actuator/refresh`端点发送POST请求，即可触发配置的重新加载。
- **自动刷新**：自动刷新通常依赖于Spring Cloud Bus和消息中间件（如RabbitMQ、Kafka等）来实现。
    - **搭建消息中间件**：根据所选的消息中间件，进行安装和配置。
    - **添加依赖**：在Config Server和Config Client中引入`spring-cloud-starter-bus-amqp`（对于RabbitMQ）或`spring-cloud-starter-bus-kafka`（对于Kafka）等依赖。
    - **配置服务与客户端**：在Config Server和Config Client的配置文件中，设置消息中间件的连接信息，并启用Spring Cloud Bus。
    - **配置Git WebHooks（可选）**：如果配置存储在Git仓库中，可以设置Git WebHooks。当Git仓库中的配置发生变更时，Git WebHooks将向Config Server发送HTTP请求，Config Server随后通过Spring Cloud Bus向所有Config Client广播刷新事件。

### reflectUtil.findMethod() 如何适配可变参数

`reflectUtil.findMethod()`适配可变参数，需将可变参数视为数组类型来处理。以下是具体步骤和示例代码：
1. **创建包含可变参数方法的类**：首先定义一个类，其中包含一个可变参数的方法。例如：
```java
public class MyClass {
    public void varArgsMethod(String... args) {
        for (String arg : args) {
            System.out.println(arg);
        }
    }
}
```
2. **获取类的Class对象**：使用`Class.forName()`方法或直接通过`类名.class`的方式获取类的`Class`对象。
```java
Class<?> myClass = MyClass.class;
```
3. **获取可变参数方法的Method对象**：调用`findMethod()`方法获取目标方法，第二个参数传入可变参数对应的数组类型`Class`对象。假设`reflectUtil`是`org.springframework.util.ReflectionUtils`，代码如下：
```java
import org.springframework.util.ReflectionUtils;
import java.lang.reflect.Method;

Method method = ReflectionUtils.findMethod(myClass, "varArgsMethod", String[].class);
```
4. **调用方法**：获取到`Method`对象后，若方法不是静态方法，需先创建类的实例，然后使用`Method.invoke()`方法调用该方法。传递参数时，将实际参数包装成对应类型的数组，再将数组作为一个参数传入`invoke`方法，且如果是引用类型参数，通常还需要将数组强转为`Object`类型。
```java
Object instance = myClass.getDeclaredConstructor().newInstance();
String[] params = {"Hello", "World", "from", "Reflection"};
method.invoke(instance, (Object) params);
```

# redis 内存淘汰策略



# Java设计实现一个基于LRU淘汰策略的缓存并且线程安全？

## 基于LRU淘汰策略的线程安全缓存实现

下面我将实现一个基于LRU（最近最少使用）淘汰策略的线程安全缓存。这个实现使用双向链表和哈希表的组合来保证O(1)时间复杂度的访问和插入操作，并使用ReentrantReadWriteLock来保证线程安全。

### 完整实现代码

```java
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

public class ThreadSafeLRUCache<K, V> {
    // 双向链表节点类
    class Node {
        K key;
        V value;
        Node prev;
        Node next;
        
        Node(K key, V value) {
            this.key = key;
            this.value = value;
        }
    }
    
    // 使用HashMap存储键值对，实现O(1)访问
    private final Map<K, Node> cache;
    // 双向链表的虚拟头节点和尾节点
    private final Node head, tail;
    // 缓存容量
    private final int capacity;
    // 读写锁保证线程安全
    private final ReadWriteLock lock = new ReentrantReadWriteLock();
    private final Lock readLock = lock.readLock();
    private final Lock writeLock = lock.writeLock();
    
    /**
     * 构造函数
     * @param capacity 缓存容量
     */
    public ThreadSafeLRUCache(int capacity) {
        this.capacity = capacity;
        this.cache = new HashMap<>();
        
        // 初始化双向链表
        this.head = new Node(null, null);
        this.tail = new Node(null, null);
        head.next = tail;
        tail.prev = head;
    }
    
    /**
     * 从缓存中获取值
     * @param key 键
     * @return 如果存在返回对应的值，否则返回null
     */
    public V get(K key) {
        readLock.lock();
        try {
            if (!cache.containsKey(key)) {
                return null;
            }
            
            Node node = cache.get(key);
            // 将访问的节点移动到链表头部（表示最近使用）
            moveToHead(node);
            return node.value;
        } finally {
            readLock.unlock();
        }
    }
    
    /**
     * 向缓存中插入键值对
     * @param key 键
     * @param value 值
     */
    public void put(K key, V value) {
        writeLock.lock();
        try {
            if (cache.containsKey(key)) {
                // 如果键已存在，更新值并移动到头部
                Node node = cache.get(key);
                node.value = value;
                moveToHead(node);
            } else {
                // 如果键不存在，创建新节点
                Node newNode = new Node(key, value);
                
                // 添加到缓存和链表头部
                cache.put(key, newNode);
                addToHead(newNode);
                
                // 如果超出容量，移除最近最少使用的节点
                if (cache.size() > capacity) {
                    Node tailNode = removeTail();
                    cache.remove(tailNode.key);
                }
            }
        } finally {
            writeLock.unlock();
        }
    }
    
    /**
     * 从缓存中移除指定键
     * @param key 要移除的键
     * @return 如果存在返回被移除的值，否则返回null
     */
    public V remove(K key) {
        writeLock.lock();
        try {
            if (!cache.containsKey(key)) {
                return null;
            }
            
            Node node = cache.get(key);
            removeNode(node);
            cache.remove(key);
            return node.value;
        } finally {
            writeLock.unlock();
        }
    }
    
    /**
     * 获取缓存当前大小
     * @return 缓存中的元素数量
     */
    public int size() {
        readLock.lock();
        try {
            return cache.size();
        } finally {
            readLock.unlock();
        }
    }
    
    /**
     * 清空缓存
     */
    public void clear() {
        writeLock.lock();
        try {
            cache.clear();
            // 重置链表
            head.next = tail;
            tail.prev = head;
        } finally {
            writeLock.unlock();
        }
    }
    
    /**
     * 将节点移动到链表头部
     * @param node 要移动的节点
     */
    private void moveToHead(Node node) {
        removeNode(node);
        addToHead(node);
    }
    
    /**
     * 将节点添加到链表头部
     * @param node 要添加的节点
     */
    private void addToHead(Node node) {
        node.prev = head;
        node.next = head.next;
        head.next.prev = node;
        head.next = node;
    }
    
    /**
     * 从链表中移除节点
     * @param node 要移除的节点
     */
    private void removeNode(Node node) {
        node.prev.next = node.next;
        node.next.prev = node.prev;
    }
    
    /**
     * 移除链表尾部节点（最近最少使用的节点）
     * @return 被移除的节点
     */
    private Node removeTail() {
        Node node = tail.prev;
        removeNode(node);
        return node;
    }
    
    @Override
    public String toString() {
        readLock.lock();
        try {
            StringBuilder sb = new StringBuilder();
            sb.append("[");
            Node current = head.next;
            while (current != tail) {
                sb.append(current.key).append("=").append(current.value);
                if (current.next != tail) {
                    sb.append(", ");
                }
                current = current.next;
            }
            sb.append("]");
            return sb.toString();
        } finally {
            readLock.unlock();
        }
    }
}
```

## 使用示例

```java
public class LRUCacheExample {
    public static void main(String[] args) {
        // 创建容量为3的LRU缓存
        ThreadSafeLRUCache<String, Integer> cache = new ThreadSafeLRUCache<>(3);
        
        // 添加元素
        cache.put("one", 1);
        cache.put("two", 2);
        cache.put("three", 3);
        System.out.println("初始缓存: " + cache); // [one=1, two=2, three=3]
        
        // 访问元素，这会改变LRU顺序
        System.out.println("获取two: " + cache.get("two")); // 2
        System.out.println("访问后缓存: " + cache); // [one=1, three=3, two=2]
        
        // 添加新元素，会淘汰最近最少使用的元素
        cache.put("four", 4);
        System.out.println("添加第四个元素后: " + cache); // [three=3, two=2, four=4]
        
        // 多线程测试
        Runnable task = () -> {
            for (int i = 0; i < 100; i++) {
                String key = "key" + i % 5;
                cache.put(key, i);
                Integer value = cache.get(key);
                System.out.println(Thread.currentThread().getName() + 
                                  " - key: " + key + ", value: " + value);
            }
        };
        
        // 创建多个线程同时访问缓存
        Thread thread1 = new Thread(task, "Thread-1");
        Thread thread2 = new Thread(task, "Thread-2");
        Thread thread3 = new Thread(task, "Thread-3");
        
        thread1.start();
        thread2.start();
        thread3.start();
        
        try {
            thread1.join();
            thread2.join();
            thread3.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        
        System.out.println("最终缓存: " + cache);
        System.out.println("缓存大小: " + cache.size());
    }
}
```

## 设计说明

1. **数据结构选择**：
    - 使用HashMap实现O(1)时间复杂度的查找
    - 使用双向链表维护访问顺序，实现O(1)时间复杂度的节点移动和删除

2. **线程安全实现**：
    - 使用ReentrantReadWriteLock而不是synchronized关键字，提高读操作的并发性
    - 读操作使用读锁，允许多个线程同时读取
    - 写操作使用写锁，确保写操作的原子性和可见性

3. **LRU淘汰策略**：
    - 当访问一个元素时，将其移动到链表头部（表示最近使用）
    - 当插入新元素且缓存已满时，移除链表尾部元素（最近最少使用）

4. **复杂度分析**：
    - 所有操作（get、put、remove）的时间复杂度均为O(1)
    - 空间复杂度为O(n)，其中n为缓存容量

这个实现提供了高效的LRU缓存功能，并且通过读写锁确保了线程安全，适用于多线程环境。

## 提示词生成原理？

好的，这是一个非常核心的AI概念。我会从简单到复杂，系统地解释“提示词生成”的原理。

首先，需要澄清一个概念：“提示词生成”通常有两个方向的理解：

1.  **用户生成提示词（Prompt Engineering）**： 人类用户如何构思、编写和优化提供给AI模型的指令或问题。这是一个技巧和艺术。
2.  **AI生成内容（AI Generation）**： AI模型如何根据接收到的提示词（Prompt）来生成文本、图片等内容。这是一个技术过程。

我将重点解释第二个，即**AI模型是如何根据你的提示词（输入）来生成内容（输出）的**，因为这是更底层的“原理”。

---

### 核心原理：概率预测与序列生成

从根本上说，当今主流的生成式AI（无论是语言模型如GPT，还是文生图模型如DALL-E、Stable Diffusion），其工作原理都是**基于从海量数据中学到的模式，进行概率预测，从而生成一个合理的序列**。

*   **对于文本模型**：序列是“词元”（tokens，可以理解为单词或词段）。
*   **对于图像模型**：序列是“潜空间中的向量”或“图像块”（patches），最终再解码成像素。

这个过程可以分解为以下几个关键步骤：

#### 1. 输入理解与编码（Input Understanding & Encoding）

当你输入一段提示词“画一只戴着礼帽的柯基犬”时，模型并不是像人类一样“理解”这句话的含义。

*   **分词（Tokenization）**：首先，模型会将你的输入文本分解成更小的单元，称为**词元（Tokens）**。例如，“画一只戴着礼帽的柯基犬”可能会被分解成 `["画", "一只", "戴着", "礼帽", "的", "柯基", "犬"]` 等tokens。
*   **向量化（Vectorization）**：每个词元都会被转换成一个高维数字向量（一长串数字）。这个向量代表了该词元在模型所学到的语义空间中的**位置**和**含义**。语义相近的词（如“犬”和“狗”），其向量在空间中的位置也更接近。
*   **上下文处理**：模型（尤其是Transformer架构）会通过**自注意力机制（Self-Attention）** 分析所有词元向量之间的关系，理解整个句子的结构和上下文。例如，它会知道“礼帽”是“戴着”的宾语，而“柯基犬”是整句话的核心主题。

至此，你的提示词已经从人类可读的文本，被转化成了模型可处理的、富含数学含义的“提示向量”。

#### 2. 内容生成（Content Generation - 推理阶段）

这是核心的“生成”环节。模型以一种**自回归（Auto-regressive）** 的方式工作，即**根据已有的内容，预测下一个最可能出现的部分**。

*   **文本生成（以GPT为例）**：
    1.  模型在处理完整个提示词后，开始预测下一个最可能出现的词元。
    2.  它基于其训练数据（整个互联网、书籍等文本）中学到的统计规律，计算出数以万计的可能词元出现的**概率分布**。例如，在提示词“中国的首都是”之后，“北京”的概率最高，“东京”、“纽约”的概率几乎为零。
    3.  模型不会总是选择概率最高的那一个（那样会生成非常枯燥可预测的文本），而是会引入**随机性（抽样）**，从高概率的候选词中随机选择一个。这个随机性由**温度（Temperature）** 参数控制。
    4.  被选中的新词元（比如“北”）会被添加到序列末尾，形成新的输入：“中国的首都是北”。
    5.  这个过程循环往复，模型根据“中国的首都是北”再次预测下一个词元（“京”），直到生成一个完整的句子或达到停止条件。

*   **图像生成（以Stable Diffusion为例）**：
    1.  原理类似，但过程更复杂。提示词首先被编码成向量。
    2.  模型从一个纯粹的**噪声图**开始。
    3.  在一步步“去噪”（Denoising）的过程中，模型根据提示词向量来指导每一步应该去除哪些噪声、保留哪些图案。提示词中的“柯基犬”、“礼帽”等概念对应的向量会引导噪声图逐渐向包含这些元素的清晰图像演变。
    4.  经过一定步数的迭代后，噪声被完全转变为一幅符合提示词描述的新图像。

#### 3. 训练阶段：如何学会这一切？

模型之所以能进行上述的概率预测，是因为它已经在海量数据上进行了**预训练（Pre-training）**。训练过程的本质是：

**“遮住”一句话后面的词，让模型预测被遮住的词，并不断调整模型内部数以亿计的参数，让它的预测越来越准确。**

通过数十亿次的这种练习，模型逐渐学会了语法、事实知识、逻辑关系，甚至不同语言和风格。它最终内化了一个极其复杂的“世界概率模型”。

---

### 为什么提示词的质量如此重要？

理解了上述原理，你就会明白为什么“提示工程”至关重要。

*   **提供丰富上下文**：好的提示词为模型提供了更丰富、更精确的上下文向量，极大地缩小了模型需要预测的概率空间，引导它走向你期望的方向。
    *   **差提示**：“画一条狗”（概率空间很大：什么狗？什么动作？什么风格？）
    *   **好提示**：“一张专业摄影照片，一只金色的拉布拉多犬在夕阳下的海滩上奔跑，溅起水花，广角镜头，温暖色调”（上下文极丰富，概率空间被高度约束，输出结果更可预测）。
*   **激活相关知识**：提示词中的关键词（如“莫奈风格”、“赛博朋克”、“专业论文”）会激活模型内部与之相关的向量区域，从而生成符合该领域特征的内容。
*   **避免歧义**：模糊的提示词会导致模型在多个高概率但可能错误的方向上进行抽样，产生不符合预期的结果。

### 总结

提示词生成的原理可以概括为：

**通过将提示词编码成高维向量，激活大型神经网络模型中在预训练阶段学到的复杂概率模型，并以自回归的方式，基于概率抽样逐步生成一个符合提示词上下文语境的新序列（文本或图像）。**

它不是魔法，而是一个极其复杂的、基于统计和概率的数学过程。你所做的每一步提示词优化，都是在为这个概率机器提供更精准的“导航坐标”。