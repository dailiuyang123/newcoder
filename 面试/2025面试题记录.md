### 面试资源

- [绘问IT面试题库](https://it.huiwenai.net/pc/group/list?id=1898270441985200129&typeId=1853061632069382145)

- [面试题](https://github.com/huiwenai/interview)
- 

# 华为

### 华为hr资格面试 2025-9-5


### 1.当前AI技术越来成熟，请你谈谈AI对程序员的影响


### 2. 对于AI技术，你是怎么看待的？

### 3. 你认为AI技术对程序员有什么影响？

A：AI技术对程序员的影响呈现出效率提升与职业重构并存的复杂态势，既带来生产力革命，也推动开发者角色向更高维度转型。以下从六个核心维度展开分析：

### 一、开发流程的智能化重构
AI工具已深度渗透编码全流程，实现从“手动编写”到“智能协作”的范式转变。以GitHub Copilot为例，其通过自然语言描述生成代码片段的能力，使基础代码编写时间缩短60%以上。阿里云通义灵码甚至能自主完成需求分析、代码生成、缺陷修复的全链路开发，5分钟即可实现传统程序员一天的工作量。这类工具不仅生成代码框架（如Flask后端路由、HTML页面结构），还能实时检测缩进错误、变量未定义等问题，并提供重构建议。

在测试环节，AI工具可自动生成覆盖3倍于传统方法的测试用例，使企业级项目测试周期缩短30%-50%。Google Gemini Code Assist更支持每月18万次代码补全，并能解释代码时间复杂度、优化异步操作逻辑，这种“编码-测试-优化”的全流程赋能，正在重塑软件开发的效率边界。

### 二、技能需求的结构性升级
程序员的能力图谱正经历三大跃迁：
1. **AI技术栈深度融合**：需掌握机器学习基础（如线性回归、神经网络）以理解AI工具原理，同时熟悉TensorFlow等框架实现模型调优。例如开发图像识别API时，需通过卷积神经网络知识调整参数优化性能。
2. **跨领域知识整合**：医疗软件开发需了解疾病诊断流程，金融AI应用需掌握风险管理知识，这种领域交叉能力成为创新关键。某金融科技企业通过AI处理重复性任务后，工程师转而专注量化模型设计，推动产品迭代效率提升40%。
3. **人机协作范式重构**：Prompt Engineering（提示工程）成为新技能，开发者需设计精准指令引导AI生成符合业务逻辑的代码。例如通过“创建用户登录界面并实现前端验证”的描述，AI可快速生成包含HTML、CSS和JavaScript的完整框架。

### 三、职业发展的两极分化
AI技术正在重塑程序员的职业坐标系：
- **传统岗位需求收缩**：初级程序员面临自动化工具和低代码平台的双重挤压，简单CRUD开发岗位减少30%。Stack Overflow调查显示，仅17%开发者“主要使用AI编写代码”，但46%表示AI处理复杂任务能力“糟糕”，这表明基础编码工作虽被替代，但复杂逻辑设计仍需人类介入。
- **新兴角色崛起**：AI系统开发工程师、算法调优师等岗位需求激增，薪资水平较普通程序员高出50%以上。某互联网企业设立“AI训练师”岗位，通过微调大模型适应量化金融场景，推动产品响应速度提升20%。
- **跨职能转型机遇**：部分开发者转向技术管理或领域专家，例如某医疗软件团队的程序员转型为AI伦理顾问，主导算法公平性审查流程。

### 四、开发者信任与效率的悖论
尽管AI工具使用率达81.4%，但信任度呈现下降趋势：46%开发者不信任AI输出，45%认为调试生成代码耗时更长。这种矛盾源于AI的“黑箱”特性——生成的代码可能存在未处理异常等漏洞，且逻辑可解释性不足。例如某电商项目因AI生成代码未考虑银联异步回调超时机制，导致支付接口故障。

效率层面同样存在“工具陷阱”：虽然AI工具使开发周期缩短70%，但Stack Overflow数据显示，开发者每天搜索答案时间仅从63%降至61%，改善幅度微弱。这表明单纯依赖工具而不优化流程，难以实现生产力质的飞跃。

### 五、行业领域的差异化冲击
不同领域受AI影响程度呈现显著差异：
- **高替代风险领域**：测试工程师（60%重复性操作）、前端开发（40%模板化工作）首当其冲。某互联网公司引入AI测试工具后，测试用例生成效率提升3倍，团队规模缩减25%。
- **中低替代风险领域**：后端开发（复杂状态管理）、算法工程师（模型可解释性需求）仍需人类主导。某金融企业在处理资金清算场景时，坚持人工设计强一致性方案，避免了AI可能引发的事务回滚风险。
- **新兴交叉领域**：量子计算与AI的融合催生新机会，例如量子机器学习可使图像识别准确率提升5%-10%，相关岗位成为稀缺资源。

### 六、应对策略与未来展望
开发者需构建“AI协作型”能力体系：
1. **技术深耕与工具驯化**：在嵌入式开发等领域建立专业壁垒，同时通过AI工具快速验证技术选型。例如某物联网团队利用AI生成硬件驱动代码后，工程师专注传感器融合算法优化，产品功耗降低15%。
2. **软技能强化**：培养需求抽象、伦理判断等不可替代能力。某教育科技企业要求程序员参与用户调研，将“沉浸式学习体验”需求转化为AI+VR应用设计，推动产品获行业创新奖。
3. **持续学习生态构建**：通过Coursera等平台学习量子计算等前沿知识，参与NeurIPS等学术会议追踪技术趋势。某开发者通过学习量子编程语言Q#，成功将AI模型训练效率提升30%。

未来，AI将从“辅助工具”进化为“协同开发者”，但人类的创造力、领域洞察和复杂决策能力仍是核心竞争力。正如蒸汽机时代工匠转向机床操作，AI时代的程序员将从代码执行者升级为技术决策者，在人机协作中定义新的价值坐标。

### 4. 你平时的学习方式


# 震雄集团

### 面试偏向业务与HR，技术比较少

#### 1. 自我介绍

#### 2. 在开发中使用的是什么系统 
- windows
- linux
- mac

#### 3. 有没有使用过工作流引擎

- Flowable
    - 流程定义（BPMN 2.0标准的XML文件）
    - 流程实例
    - 任务
    - 网关（用于控制流程的流转） 
    - 条件表达式（）
    - 边界事件
    - 流程定义
    - 集成到springboot中：POM 依赖坐标
      - flowable-spring-boot-starter 6.7.2

- Activiti

#### 4. 描述一个项目，并给出项目所使用的技术

### 5. 有没有使用过 Oracle 数据库？

# 华为OD 2025-9-8

### 一分钟自我介绍

### 问了十几个Java相关面试题

  - 线程和进程的区别？
  > 答案：进程：系统运行的基本单位，进程在运行过程中都是相互独立，但是线程之间运行可以相互影响。
    线程：独立运行的最小单位，一个进程包含多个线程且它们共享同一进程内的系统资源
    进程间通过管道、 共享内存、信号量机制、消息队列通信
  - 介绍一下常见的工厂模式？
    - 简单工厂
    - 工厂方法
    - 抽象工厂
  - 设计模式扩展
    > Spring 常用设计模式 \
    单例模式:bean默认都是单例的 \
    原型模式:指定作用域为prototype \
    工厂模式:BeanFactory \
    模板方法:postProcessBeanFactory,onRefresh,initPropertyValue \
    策略模式:XmlBeanDefinitionReader,PropertiesBeanDefinitionReader \
    观察者模式:listener,event,multicast \
    适配器模式:Adapter \
    装饰者模式:BeanWrapper \
    责任链模式:使用aop的时候会先生成一个拦截器链 \
    代理模式:动态代理
  - spring cloud 常见的组件？
    - 服务注册用发现
      - Nacos(功能全面)
      - Consul(强一致性)
    - 服务调用组件
      - OpenFeign + Spring Cloud LoadBalancer
    - 网关
      - spring cloud gateway
    - 容错与流量配置
      - Sentinel（高并发）或 Resilience4J（轻量）
    - 配置管理
      - Nacos Config
    - 负载均衡与服务调用
      - OpenFeign + Spring Cloud LoadBalancer
    - 分布式追踪
      - Micrometer Tracing + Zipkin
    - 消息驱动
    - 安全认证
      - Spring Cloud Security + OAuth2/JWT  
    - 分布式事务
      - Seata
        -  AT模式 保证常见关系型数据库分布式事务的一致性
          - AT模式是一种无侵入式的分布式事务模式（本地事务+补偿机制），使用与关系型数据库如（MySql）,核心依赖（undo log）回滚日志和全局锁保持一致（XID）全局事务ID
        - TCC模式 保证常见关系型数据库分布式事务的一致性
        - SAGA模式 保证常见关系型数据库分布式事务的一致性

# 金蝶 2025-9-9

### Spring Cloud 问的很多？
    
- Spring Cloud 常用组件？

    - 服务注册与发现 （open feign (alibaba)   ）

- Spring Cloud 服务间调用使用的是什么组件？
  - open feign + spring cloud load balancer

- 服务间调用如何保证数据安全？
  - ：
  - 
## 消息队列问的很深

## 为什么选择kafka?

## - 请说一下rabbitMQ 中 vhost 的作用？

  >  RabbitMQ 中的 **Virtual Host**（虚拟主机，简称 vhost）是一个非常重要的逻辑隔离机制。你可以把它想象成一台物理服务器（RabbitMQ Broker）里的多个独立「迷你消息服务器」，每个都有自己全套的资源（交换机、队列、绑定关系）和权限体系。

| 作用与场景         | 说明                                                                 | 举例                                     |
| :----------------- | :------------------------------------------------------------------- | :--------------------------------------- |
| **资源隔离**       | 不同vhost间的交换机、队列、消息绝对隔离，无法直接通信。            | `/app1` 的订单队列无法被 `/app2` 消费        |
| **权限控制**       | 用户权限基于vhost分配，实现安全管控。                       | 用户A可管理`/prod`，但只能读`/test`         |
| **多环境支持**     | 同一集群上为不同环境（开发、测试、生产）创建独立的vhost。                 | `/dev`, `/test`, `/prod`                 |
| **多租户架构**     | SaaS应用中，为不同客户分配独立vhost，实现数据隔离。                      | `/tenant_alibaba`, `/tenant_tencent`     |
| **命名空间**       | 资源（如队列名）只需在所属vhost内唯一，不同vhost可重名。 | `/app1/logs` 和 `/app2/logs` 可以共存且互不影响 |

默认情况下，RabbitMQ 自带一个名为 `/` 的 vhost。**强烈建议在生产环境中创建并使用新的 vhost**，而不是继续使用这个默认的 vhost，以避免潜在混淆。

### 🔧 管理 Vhost

管理 vhost 的常用方式有以下几种：

1.  **命令行工具 (`rabbitmqctl`)**: 最直接的方式，适合脚本化和服务器管理。
    ```bash
    # 创建 vhost
    rabbitmqctl add_vhost /your_vhost_name
    # 删除 vhost
    rabbitmqctl delete_vhost /your_vhost_name
    # 列出所有 vhost
    rabbitmqctl list_vhosts
    ```
    创建后通常需为用户授权：
    ```bash
    # 授予用户 alice 对 vhost /your_vhost_name 的所有操作权限
    rabbitmqctl set_permissions -p /your_vhost_name alice ".*" ".*" ".*"
    ```


2.  **Web 管理界面**: 通过浏览器访问 RabbitMQ 的 Web 管理界面（默认端口 `15672`），在 **Admin** -> **Virtual Hosts** 标签页中，可以直观地创建、删除 vhost 以及管理其权限。

3.  **HTTP API**: 通过调用 RabbitMQ 提供的 HTTP API 管理 vhost，便于自动化集成。

### 📌 客户端连接指定 Vhost

生产者和消费者在连接 RabbitMQ 时，**必须指定要使用的 vhost**（如果使用默认的 `/`，有时客户端库可能允许省略，但显式指定是好习惯）。

以下是不同语言的连接示例：

-   **Java (使用 amqp-client)**:
    ```java
    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");
    factory.setVirtualHost("/your_vhost_name"); // 指定 vhost
    factory.setUsername("your_username");
    factory.setPassword("your_password");
    Connection connection = factory.newConnection();
    ```



### 💡 最佳实践与注意事项

*   **清晰的命名**：为vhost起一个有意义的名字，如按项目`/project-x`、按环境`/prod`、按团队`/team-data`。
*   **权限最小化原则**：遵循**最小权限原则**，只授予用户必要的权限。
*   **区分环境**：为开发、测试、生产等不同环境创建不同的vhost，并确保应用程序连接配置正确，避免误操作。
*   **监控与清理**：定期监控各个vhost的资源使用情况（连接数、队列数、消息速率等），并清理不再使用的vhost。

### ⚠️ 需要注意的要点

-   **vhost 不直接存储消息**：消息存储在队列中，而队列属于特定的 vhost。
-   **连接必须指定 vhost**：客户端连接时必须指定一个已存在且有权限的 vhost，否则连接会失败。
-   **默认 vhost 的风险**：生产环境中建议避免使用默认的 `/` vhost，并为不同应用或环境创建独立的 vhost，**严禁不同环境共用同一 vhost**。
-   **权限是关键**：vhost的隔离安全性严重依赖于正确的用户和权限设置。

- rabbit mq 与kefka 对比优劣势？

- kafka 消费端如何保证数据一致性？
    - 1.ISR（同步副本集）：每个分区维护一个与 Leader 同步的副本列表，只有 ISR 中的副本才被视为有效备份。当生产者设置 acks=all 时，消息需被所有 ISR 副本写入后才确认成功，确保数据不丢失
    - 2.幂等性处理
    - 3.原子提交：通过 Kafka 事务将消息处理与偏移量提交绑定，确保二者要么同时成功，要么回滚。
    - 4.kafka 默认是异步提交，异步提交会丢失数据； 
    - 同步提交：在消息处理完成后调用 **consumer.commitSync()**，确保偏移量提交成功。适合对一致性要求高的场景


## 数据库

## MySQL一张数据量很大的表如何优化查询速度？

### 核心思路
优化的核心思路可以归纳为以下几点：
1.  **减少数据量**：让数据库引擎需要扫描和计算的数据尽可能的少。
2.  **减少计算量**：优化查询逻辑，避免复杂的计算和临时表。
3.  **转换思路**：用空间换时间，通过增加硬件资源或冗余数据来提升速度。
4.  **终极方案**：当单表优化到极限时，必须进行架构上的拆分。

---

### 一、 基础且高效的优化（首选方案）

这些方法成本低、见效快，应优先考虑。

#### 1. 优化索引 (Index Optimization)
索引是优化查询最直接有效的手段。

*   **确保查询使用了合适的索引**： 使用 `EXPLAIN` 命令分析你的慢查询，查看是否使用了索引，以及使用的是哪个索引。
    ```sql
    EXPLAIN SELECT * FROM your_large_table WHERE some_column = 'value';
    ```
    关注 `key`（使用的索引）、`rows`（预估扫描行数）、`type`（访问类型，`const`, `ref`, `range` 为佳，`ALL` 为全表扫描需避免）。

*   **为 `WHERE`, `JOIN`, `ORDER BY`, `GROUP BY` 子句中的列创建索引**。

*   **避免冗余和未使用的索引**： 索引会降低写操作（INSERT/UPDATE/DELETE）的速度并占用空间。定期检查并删除未使用的索引。

*   **使用覆盖索引 (Covering Index)**： 如果索引包含了查询所需要的所有字段，MySQL就可以直接从索引中获取数据，而不需要回表查询数据行，效率极高。
    *   **坏**：`SELECT * FROM table WHERE indexed_column = 'value’;` (需要回表)
    *   **好**：`SELECT indexed_column, other_indexed_column FROM table WHERE indexed_column = 'value’;` (可能覆盖索引)

*   **注意索引的选择性**： 为选择性高的列创建索引效果更好（例如，身份证号、用户名）。选择性低的列（如：性别、状态标志）加索引效果不大，有时反而更差。

*   **前缀索引 (Prefix Indexes)**： 对于 TEXT/BLOB 或很长的 VARCHAR 列，可以只对列的前 N 个字符创建索引，节省空间。
    ```sql
    CREATE INDEX idx_name ON your_table (long_column_name(255));
    ```

#### 2. 优化SQL查询语句 (Query Optimization)
很多时候，慢查询是因为SQL写得不好。

*   **只获取需要的列**： 坚决避免 `SELECT *`，尤其是表中有TEXT/BLOB等大字段时。明确指定需要的列。
*   **使用高效的查询条件**：
    *   避免在 WHERE 子句中对字段进行函数操作（如 `WHERE YEAR(create_time) = 2023`），这会导致索引失效。应改为范围查询（`WHERE create_time BETWEEN '2023-01-01' AND '2023-12-31'`）。
    *   小心使用 `OR`，可能导致全表扫描。可以考虑用 `UNION` 替代。
    *   避免使用 `!=` 或 `NOT IN`，它们通常无法使用索引。
*   **优化联表查询 (JOIN)**：
    *   确保 `ON` 或 `USING` 子句中的列上有索引。
    *   被驱动表（第二个表）的连接列必须有索引。
    *   小表驱动大表。

---

### 二、 中级优化（表结构和系统层面）

当基础优化做到极致后，可以考虑这些方案。

#### 1. 分区表 (Partitioning)
将一张大表在物理上分割成多个更小的、更易管理的部分（分区），但对应用来说仍然是一张逻辑表。

*   **适用场景**： 数据有明显的逻辑区间，比如按时间（年/月）、地域范围等。常用于日志表、历史订单表。
*   **优点**： 查询时，优化器可以自动只扫描所需的分区（**分区裁剪**），极大减少扫描数据量。
*   **缺点**： 对业务透明，但管理复杂，且有很多限制（如所有分区必须使用相同的存储引擎、主键/唯一索引必须包含分区键）。
*   **示例**：
    ```sql
    CREATE TABLE sales (
        id INT NOT NULL,
        purchase_date DATE NOT NULL
    )
    PARTITION BY RANGE(YEAR(purchase_date)) (
        PARTITION p0 VALUES LESS THAN (1990),
        PARTITION p1 VALUES LESS THAN (2000),
        PARTITION p2 VALUES LESS THAN (2010),
        PARTITION p3 VALUES LESS THAN (2020),
        PARTITION p4 VALUES LESS THAN MAXVALUE
    );
    -- 查询2023年的数据，只会扫描2023年所在的分区
    SELECT * FROM sales WHERE purchase_date BETWEEN '2023-01-01' AND '2023-12-31';
    ```

#### 2. 使用更快的存储设备
**将数据库放在SSD硬盘上**。IO瓶颈往往是数据库性能的最大杀手，SSD的随机读写能力远超机械硬盘，能极大提升查询和更新速度。

#### 3. 调整服务器参数 (Configuration Tuning)
优化MySQL的配置参数（`my.cnf` / `my.ini`），这对性能提升也很关键。

*   **`innodb_buffer_pool_size`**： **这是最重要的参数**。InnoDB缓冲池用于缓存表数据和索引。建议设置为可用物理内存的 **70%-80%**。让热数据尽可能留在内存中。
*   **`innodb_buffer_pool_instances`**： 如果缓冲池很大（比如 > 16GB），可以设置多个实例来减少锁竞争。
*   **`max_connections`**： 合理设置最大连接数，避免过多连接耗尽资源。
*   **`query_cache_size`**： **注意：在MySQL 5.7.20开始已弃用，8.0中已移除**。如果你的版本较早，可以考虑是否启用查询缓存，但对于写频繁的应用，查询缓存可能弊大于利。

**警告**： 不要盲目修改参数，最好参考官方文档或使用像 `MySQLTuner` 这样的工具来分析当前配置。

---

### 三、 高级/架构优化（应对海量数据）

当单表优化到极限，数据量持续增长时，必须从架构上动刀。

#### 1. 读写分离 (Read/Write Splitting)
*   **主从复制 (Master-Slave Replication)**： 搭建一个主库（Master）负责处理写操作（INSERT/UPDATE/DELETE），多个从库（Slave）通过复制同步主库的数据，负责处理读操作（SELECT）。
*   **优点**： 分摊数据库压力，提升读性能。从库还可以用于备份和数据分析，不影响主库。
*   **缺点**： 存在主从同步延迟，对数据一致性要求非常高的读操作可能需要读主库。

#### 2. 垂直拆分 (Vertical Sharding)
*   **做法**： 将一个包含很多字段的大表，按访问频度拆分成多个小表（例如，将常用的主字段放在一个表，将不常用的大字段如`TEXT`、`BLOB`放到另一个扩展表）。
*   **优点**： 使得核心查询需要扫描的数据页更少，IO效率更高。
*   **缺点**： 应用层需要做相应修改，查询时需要联表。

#### 3. 水平拆分/分库分表 (Horizontal Sharding)
这是处理亿级以上数据的终极大招。

*   **做法**： 将一张表的数据**按某种规则（分片键）** 分散到多个数据库或多个数据表中。例如，按用户ID哈希取模，或按时间范围。
*   **优点**： 从根本上解决了单表、单库的性能瓶颈和容量上限问题。
*   **缺点**：
    *   **复杂度极高**： 应用层需要大幅修改，需要中间件（如 ShardingSphere, MyCat, Vitess）来管理分片路由。
    *   跨分片查询、聚合、排序、事务变得非常复杂和困难。
    *   扩容（如增加分片数量）操作繁琐。

**常见的分片策略**：
*   **范围分片**： 按时间或ID范围（如1-100万在表1，100万-200万在表2）。容易产生热点数据。
*   **哈希分片**： 对分片键（如`user_id`）进行哈希取模，均匀分布数据。扩容时数据迁移量大。
*   **地理位置分片**： 根据用户地域分到不同的数据库。

---

### 总结与操作流程

当你面对一张大表时，建议按以下步骤进行排查和优化：

1.  **定位问题**： 使用**慢查询日志 (Slow Query Log)** 找出最耗时的SQL。
2.  **分析SQL**： 对慢SQL使用 **`EXPLAIN`** 命令，分析其执行计划，看是否索引失效、是否全表扫描。
3.  **优化索引**： 根据 `EXPLAIN` 的结果，添加或调整索引。这是最快的方法。
4.  **优化SQL**： 重写SQL，避免 `SELECT *`，避免在WHERE子句中使用函数等。
5.  **考虑分区**： 如果数据有明显的冷热特性（如时间），考虑使用分区表。
6.  **调整配置**： 优化 `innodb_buffer_pool_size` 等核心参数。
7.  **硬件升级**： 使用SSD硬盘，增加内存。
8.  **架构升级**： 如果以上所有方法都无法满足需求，再考虑**读写分离**和**分库分表**这些重量级方案。


## NOSQL

- 你们经常用的NoSQL数据库有哪些？

## 运维Linux相关
 - docker file 会写吗？
 - 常见Linux命令
 - Spring boot jar包 启动命令行
 - 服务报警你们是如何做的，如何处理？

### 前端 
- vue 生命周期函数有哪些？
> 1. 创建阶段
     beforeCreate（选项式 API）
     触发时机：组件实例初始化后，数据观测和事件配置前。
     用途：初始化非响应式数据或全局配置（如第三方库初始化）。
     组合式 API 替代：逻辑直接写在 setup 函数中。
     created（选项式 API）
     触发时机：实例创建完成，数据观测和事件初始化后。
     用途：访问组件数据、发送异步请求（如获取初始数据）。
     组合式 API 替代：逻辑直接写在 setup 函数中。
>2. 挂载阶段
   beforeMount（选项式 API）
   触发时机：模板编译完成，但未挂载到真实 DOM。
   用途：修改虚拟 DOM 或初始化非 DOM 资源。
   组合式 API：onBeforeMount（需从 vue 导入）。
   mounted（选项式 API）
   触发时机：组件挂载到 DOM 后，可安全访问真实 DOM。
   用途：操作 DOM（如初始化图表库）、发送依赖 DOM 的异步请求。
   组合式 API：onMounted（示例见下方代码）。
>3. 更新阶段
   beforeUpdate（选项式 API）
   触发时机：响应式数据变化，虚拟 DOM 重新渲染前。
   用途：获取更新前的状态（如滚动位置），避免在此阶段修改数据。
   组合式 API：onBeforeUpdate。
   updated（选项式 API）
   触发时机：数据和 DOM 更新完成后。
   用途：依赖最新 DOM 状态的操作（如调整布局），避免在此修改数据导致循环更新。
   组合式 API：onUpdated。
>4. 卸载阶段
   beforeUnmount（选项式 API，替代 Vue 2 的 beforeDestroy）
   触发时机：组件卸载前，DOM 仍存在。
   用途：清理定时器、解绑事件监听、取消网络请求等资源释放操作。
   组合式 API：onBeforeUnmount。
   unmounted（选项式 API，替代 Vue 2 的 destroyed）
   触发时机：组件卸载后，所有指令和事件监听器已解绑。
   用途：执行最终清理（如日志记录），此时无法访问组件实例。
   组合式 API：onUnmounted。

# vivo 外包 2025-9-9

## 离职原因

## 平常如何学习的？

## 数据库相关

## 说一下SQL执行流程

## 了解MySQL索引吗？说一下B+索引，叶子节点存放了几条数据？

## 你知不知道MVCC特性？

## 你在华为有没有遇到慢SQL，是如何优化的？

# Java核心

## jvm 如何计算实例对象占用内存的？

## new一个对象，对象的运行流程？

## redis

## 有没有用到redis，你们都是用在什么场景？

## redis String 内部是如何实现的？

## Mysql 读写分离如何保证事务的一致性?

这是一个非常经典且重要的问题。数据库读写分离在提升系统性能的同时，也确实引入了数据一致性的挑战。首先，我们需要清晰地理解问题的根源。

### 为什么读写分离会导致数据不一致？

根本原因在于**主从复制是异步的**。
1.  一个写请求（增、删、改）在主库上完成。
2.  主库将此次变更写入**二进制日志（binlog）**。
3.  从库的**I/O线程**异步地拉取主库的binlog。
4.  从库的**SQL线程**异步地重放（replay）这些binlog，从而应用更改。

步骤3和4的异步性导致了**复制延迟（Replication Lag）**，即从库的数据落后于主库。因此，用户在写入后立刻去从库查询，可能会查不到刚写入的数据，或者读到旧数据。

---

保证数据一致性没有“银弹”，需要根据业务场景在**一致性强度**和**系统性能**之间做出权衡。以下是几种常见的解决方案，从强一致性到弱一致性排列。

### 一、强一致性方案（牺牲部分性能，保证绝对一致）

这类方案要求读操作也走主库，完全规避复制延迟。

1.  **强制读主（Master Read）**
    *   **做法**：所有对数据一致性要求高的读请求（如“读写后立刻查询”、“查询账户余额”）都不经过从库，直接发往主库。
    *   **优点**：实现简单，绝对保证强一致性。
    *   **缺点**：完全丧失了读写分离带来的读性能提升，主库压力大。通常只用于关键业务。

2.  **分布式事务/强一致性协议**
    *   **做法**：使用如Paxos、Raft等分布式共识算法，确保数据在写入主库的同时，必须在多数从库上也同步完成才算成功。或者使用MySQL Group Replication等强一致性集群方案。
    *   **优点**：真正实现了数据库层面的强一致性。
    *   **缺点**：性能开销极大，写入延迟非常高，实现和运维复杂。通常用于金融核心等对一致性有极端要求的场景，一般不作为读写分离的常规解决方案。

### 二、最终一致性方案（保证性能，接受短暂不一致）

这是最常用的思路，系统承认存在短暂的不一致，但通过一些技巧让用户尽可能感知不到，或快速变为一致。

1.  **半同步复制（Semi-Synchronous Replication）**
    *   **做法**：在主库执行完一个事务后，**至少等待一个从库接收并确认**（不一定要重放完成）binlog后，才返回成功给客户端。
    *   **优点**：相比异步复制，显著降低了数据丢失的风险（主库宕机时，至少有一个从库有最新数据），也缩短了复制延迟窗口。
    *   **缺点**：比异步复制性能稍差，因为多了一次网络往返的耗时。如果从库一直不确认，超时后会自动降级为异步复制。

2.  **中间件/代理层判断**
    *   **做法**：在数据库中间件（如ShardingSphere、ProxySQL）或应用层进行路由判断。
        *   **写后读主**：在同一个会话（Session/Connection）中，如果执行了写操作，在此会话后续的一定时间窗口内（如500ms）的所有读请求都自动路由到主库。可以通过在中间件中设置一个`last_write_time`的标记来实现。
        *   **基于Hint的路由**：对于特定必须读主的请求，通过在SQL注释中加入特殊标记（如 `/* master */ SELECT ...`），让中间件识别并将其路由到主库。

3.  **数据库外部缓存**
    *   **做法**：写操作不仅更新数据库，同时更新Redis等高速缓存。读操作优先查询缓存。
    *   **优点**：性能极高，既能分担数据库读压力，又能保证读到最新数据。
    *   **缺点**：系统复杂度升高，需要维护缓存和数据库之间的数据一致性（缓存过期、穿透、击穿、雪崩等问题）。

4.  **关键业务查询走主库**
    *   **做法**：这是对“强制读主”的细化。不是所有读都走主库，而是根据业务逻辑区分。
        *   **读用户自己的信息**：用户刚更新了个人信息，后续立刻查看，这类请求走主库。
        *   **读别人的信息/非关键数据**：浏览新闻列表、查看他人主页等，这类请求走从库。
    *   **优点**：在性能和一致性之间取得了很好的平衡，是实践中非常常用的模式。

### 三、应对方案总结与选型建议

| 方案 | 一致性强度 | 性能影响 | 实现复杂度 | 适用场景 |
| :--- | :--- | :--- | :--- | :--- |
| **强制读主** | **强一致** | 高（主库压力大） | 低 | 核心业务，如支付、余额查询 |
| **分布式协议** | **强一致** | 非常高（写入延迟高） | 极高 | 金融核心交易，不计成本保证一致 |
| **半同步复制** | **最终一致**（但延迟极短） | 中（比异步复制差） | 中 | 通用方案，平衡数据安全与性能 |
| **写后读主/中间件** | **最终一致**（会话内强一致） | 低 | 中 | 最推荐的通用方案，用户体验好 |
| **外部缓存** | **最终一致**（缓存有效期） | 极高（读缓存快） | 高 | 读多写少，对响应速度要求极高 |
| **业务区分读写** | **最终一致** | 低 | 中 | 需要业务代码配合，通用性强 |

### 实践中的组合策略

在实际生产环境中，通常会**组合使用**多种方案，而不是单一选择：

1.  **基础架构**：采用**半同步复制**作为数据库底层保障，确保数据不会丢失且延迟较低。
2.  **架构设计**：引入**中间件**，并默认开启**写后读主**策略，保证用户在同一会话内感知不到延迟。
3.  **业务开发**：在业务代码中，对**关键业务逻辑**（如订单创建后的查询）显式指定`/* master */` hint，强制走主库。
4.  **性能加速**：对**热点数据**（如商品详情）使用**Redis缓存**，进一步提升读性能并降低数据库压力。

**结论：**
保证读写分离下的数据一致性，核心思路是 **“根据业务场景分级处理”** 。大部分场景接受最终一致性，通过**写后读主、业务区分**等技巧来提升用户体验；小部分核心场景则通过**强制读主**来保证强一致性。没有完美的方案，只有最适合业务现状的权衡。


## 卓望

## SpringCloud服务调用组件OpenFeign如何增加请求头？

在 Spring Cloud OpenFeign 中添加请求头，核心是根据 **请求头的作用范围（局部/全局）** 和 **动态性需求** 选择不同方案。以下是具体代码实现和详细说明，覆盖所有常用场景：


## 一、局部请求头（仅作用于单个 Feign 方法/接口）
局部请求头适用于“特定接口需要专属请求头”的场景，比如某个接口需要单独的 `App-Secret` 或 `Content-Type`。

### 1. 方案1：通过 `@RequestMapping` 系列注解的 `headers` 属性
直接在 `@GetMapping`/`@PostMapping` 等注解中通过 `headers` 属性硬编码或引用配置文件中的请求头。

#### 步骤1：配置文件（可选，用于动态值）
若请求头值需要动态配置（如从 `application.yml` 读取），先定义配置：
```yaml
# application.yml
feign:
  headers:
    app-secret: "dev_123456"  # 动态配置的请求头值
    content-type: "application/json;charset=UTF-8"
```

#### 步骤2：Feign 接口代码
```java
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestBody;

// 声明 Feign 客户端（name 为服务名，url 可用于本地调试）
@FeignClient(name = "user-service", url = "${feign.url.user-service:http://localhost:8081}")
public interface UserFeignClient {

    // 方式1：直接硬编码请求头
    @PostMapping(value = "/api/user/save", headers = "Content-Type=application/json;charset=UTF-8")
    Boolean saveUserHardCode(@RequestBody UserDTO userDTO);

    // 方式2：引用配置文件中的请求头（推荐，支持动态修改）
    @PostMapping(
        value = "/api/user/query",
        headers = {
            "Content-Type=${feign.headers.content-type}",  // 引用配置的 Content-Type
            "App-Secret=${feign.headers.app-secret}"       // 引用配置的 App-Secret
        }
    )
    UserVO queryUserBySecret(@RequestBody UserQueryDTO queryDTO);
}
```


### 2. 方案2：通过 `@RequestHeader` 注解（支持动态参数）
若请求头值需要从调用方传入（如动态的 `Authorization` Token），使用 `@RequestHeader` 注解绑定参数。

#### Feign 接口代码
```java
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestHeader;
import org.springframework.web.bind.annotation.RequestParam;

@FeignClient(name = "order-service")
public interface OrderFeignClient {

    // 场景1：单个动态请求头（如 Authorization Token）
    @GetMapping("/api/order/detail")
    OrderVO getOrderDetail(
        @RequestParam("orderId") Long orderId,
        // 从调用方传入 Token，绑定到 Authorization 请求头
        @RequestHeader("Authorization") String token
    );

    // 场景2：多个动态请求头（用 MultiValueMap 接收，支持一个 key 对应多个 value）
    @GetMapping("/api/order/list")
    PageInfo<OrderVO> getOrderList(
        @RequestParam("userId") Long userId,
        // 接收多个请求头（如 Authorization、User-Region）
        @RequestHeader MultiValueMap<String, String> dynamicHeaders
    );
}
```

#### 调用方代码（Controller 层示例）
```java
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.util.LinkedMultiValueMap;
import org.springframework.util.MultiValueMap;

@RestController
public class OrderController {

    private final OrderFeignClient orderFeignClient;

    // 构造注入 Feign 客户端
    public OrderController(OrderFeignClient orderFeignClient) {
        this.orderFeignClient = orderFeignClient;
    }

    // 调用场景1：传入单个 Token
    @GetMapping("/order/detail")
    public OrderVO getOrderDetail(@RequestParam("orderId") Long orderId) {
        String userToken = "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."; // 从 Session/Redis 中获取
        return orderFeignClient.getOrderDetail(orderId, userToken);
    }

    // 调用场景2：传入多个动态请求头
    @GetMapping("/order/list")
    public PageInfo<OrderVO> getOrderList(@RequestParam("userId") Long userId) {
        MultiValueMap<String, String> headers = new LinkedMultiValueMap<>();
        headers.add("Authorization", "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...");
        headers.add("User-Region", "Shanghai"); // 额外的请求头
        headers.add("Accept-Language", "zh-CN");
        return orderFeignClient.getOrderList(userId, headers);
    }
}
```


### 3. 方案3：通过 `@Headers` 注解（Feign 原生注解）
`@Headers` 是 Feign 原生注解，可作用于类（所有方法生效）或方法（单个方法生效），但需注意：
- 若使用 `@Headers`，需配置 Feign 原生契约（默认是 SpringMVC 契约，不识别 `@Headers`）。

#### 步骤1：配置 Feign 原生契约
```java
import feign.Contract;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

// Feign 配置类（注意：若加 @Configuration，需避免被 Spring 扫描到全局生效，建议放在非主包下）
public class FeignNativeConfig {

    // 配置 Feign 原生契约（支持 @Headers、@RequestLine 等原生注解）
    @Bean
    public Contract feignContract() {
        return new Contract.Default();
    }
}
```

#### 步骤2：Feign 接口代码（使用原生注解）
```java
import feign.Headers;
import feign.Param;
import feign.RequestLine;
import org.springframework.cloud.openfeign.FeignClient;

// 指定配置类，启用原生契约
@FeignClient(name = "product-service", configuration = FeignNativeConfig.class)
@Headers("Content-Type: application/json;charset=UTF-8") // 类级别：所有方法都带此请求头
public interface ProductFeignClient {

    // 方法级别：额外添加 Authorization 请求头（支持动态参数，用 {token} 占位）
    @RequestLine("GET /api/product/{productId}") // 原生请求方式+路径
    @Headers("Authorization: {token}")
    ProductVO getProductById(
        @Param("productId") Long productId, // 路径参数，对应 {productId}
        @Param("token") String token        // 请求头参数，对应 {token}
    );
}
```


## 二、全局请求头（作用于所有 Feign 接口/指定 Feign 客户端）
全局请求头适用于“所有接口都需要统一携带的请求头”，比如 `Token`、`App-Id`、`User-Agent` 等，无需在每个方法中重复定义。

核心是实现 Feign 提供的 `RequestInterceptor` 接口，通过拦截器统一添加请求头。


### 1. 方案1：全局生效（所有 Feign 客户端）
配置一个全局的 `RequestInterceptor`，所有 Feign 调用都会携带该请求头。

#### 代码实现
```java
import feign.RequestInterceptor;
import feign.RequestTemplate;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;

import javax.servlet.http.HttpServletRequest;

// 全局 Feign 配置（加 @Configuration 后，会被所有 Feign 客户端继承）
@Configuration
public class GlobalFeignConfig {

    @Bean
    public RequestInterceptor globalRequestInterceptor() {
        return new RequestInterceptor() {
            @Override
            public void apply(RequestTemplate template) {
                // 1. 添加固定请求头（所有请求都携带）
                template.header("App-Id", "feign-demo-1.0");
                template.header("User-Agent", "SpringCloud-OpenFeign");

                // 2. 添加动态请求头（如从当前请求中获取 Token，传递给下游服务）
                // 注意：若 Feign 调用是异步的（如 @Async），RequestContextHolder 可能获取不到请求，需特殊处理
                ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
                if (attributes != null) {
                    HttpServletRequest request = attributes.getRequest();
                    // 从当前请求的 Header 中获取 Authorization，传递给 Feign 调用
                    String token = request.getHeader("Authorization");
                    if (token != null && !token.isEmpty()) {
                        template.header("Authorization", token);
                    }
                }
            }
        };
    }
}
```


### 2. 方案2：指定 Feign 客户端生效（局部全局）
若只需某个 Feign 客户端携带全局请求头，无需影响其他客户端，可在 `@FeignClient` 的 `configuration` 属性中指定专属配置类。

#### 步骤1：专属 Feign 配置类（无 @Configuration 注解，避免全局生效）
```java
import feign.RequestInterceptor;
import feign.RequestTemplate;
import org.springframework.context.annotation.Bean;

// 专属配置类（不加 @Configuration，仅在指定 Feign 客户端中生效）
public class PaymentFeignConfig {

    @Bean
    public RequestInterceptor paymentRequestInterceptor() {
        return template -> {
            // 仅 PaymentFeignClient 会携带这些请求头
            template.header("Payment-App-Key", "payment_789");
            template.header("Encrypt-Type", "AES");
        };
    }
}
```

#### 步骤2：Feign 接口指定配置类
```java
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.PostMapping;
import org.springframework.web.bind.annotation.RequestParam;

// 仅当前 Feign 客户端使用 PaymentFeignConfig，携带专属全局请求头
@FeignClient(name = "payment-service", configuration = PaymentFeignConfig.class)
public interface PaymentFeignClient {

    @PostMapping("/api/payment/create")
    Boolean createPayment(@RequestParam("orderId") Long orderId);
}
```


## 三、关键注意事项
1. **异步调用的请求头传递问题**  
   若 Feign 调用在 `@Async` 异步方法中执行，`RequestContextHolder` 会丢失当前 HTTP 请求上下文，导致无法获取 `Authorization` 等动态头。  
   解决方案：手动传递请求头参数，或使用 `ThreadLocal` 存储上下文。

2. **请求头重复问题**  
   若多个方案同时添加同一请求头（如全局拦截器和 `@RequestHeader`），Feign 会保留所有值（多个相同 Key 的请求头），而非覆盖。若需避免重复，需在代码中判断是否已存在该请求头。

3. **Feign 契约冲突**  
   使用 `@Headers` 等原生注解时，必须配置 `Contract.Default()`，否则注解不生效；而配置原生契约后，`@GetMapping`/`@PostMapping` 等 SpringMVC 注解会失效，需二选一。


通过以上方案，可覆盖 OpenFeign 中所有添加请求头的场景，根据实际需求选择局部或全局方案即可。

## Spring Cloud Config 修改配置能够实时刷新吗？

Spring Cloud Config修改配置能够实时刷新。它提供了手动刷新和自动刷新两种机制来实现配置的实时刷新，以确保服务能够实时获取最新的配置信息。具体如下：
- **手动刷新**：
    - **添加依赖**：在Config Client的`pom.xml`中引入`spring-boot-starter-actuator`依赖，该依赖提供了刷新端点。
    - **配置暴露端点**：在Config Client的配置文件中，设置`management.endpoints.web.exposure.include=*`，以暴露所有的Actuator端点，包括用于刷新配置的`/refresh`端点。
    - **标记Bean**：使用`@RefreshScope`注解标记需要动态刷新的Bean。当配置更新并触发刷新端点后，这些Bean将重新初始化，并应用新的配置值。
    - **触发刷新**：通过工具如Postman或curl命令，向Config Client的`/actuator/refresh`端点发送POST请求，即可触发配置的重新加载。
- **自动刷新**：自动刷新通常依赖于Spring Cloud Bus和消息中间件（如RabbitMQ、Kafka等）来实现。
    - **搭建消息中间件**：根据所选的消息中间件，进行安装和配置。
    - **添加依赖**：在Config Server和Config Client中引入`spring-cloud-starter-bus-amqp`（对于RabbitMQ）或`spring-cloud-starter-bus-kafka`（对于Kafka）等依赖。
    - **配置服务与客户端**：在Config Server和Config Client的配置文件中，设置消息中间件的连接信息，并启用Spring Cloud Bus。
    - **配置Git WebHooks（可选）**：如果配置存储在Git仓库中，可以设置Git WebHooks。当Git仓库中的配置发生变更时，Git WebHooks将向Config Server发送HTTP请求，Config Server随后通过Spring Cloud Bus向所有Config Client广播刷新事件。

### reflectUtil.findMethod() 如何适配可变参数

`reflectUtil.findMethod()`适配可变参数，需将可变参数视为数组类型来处理。以下是具体步骤和示例代码：
1. **创建包含可变参数方法的类**：首先定义一个类，其中包含一个可变参数的方法。例如：
```java
public class MyClass {
    public void varArgsMethod(String... args) {
        for (String arg : args) {
            System.out.println(arg);
        }
    }
}
```
2. **获取类的Class对象**：使用`Class.forName()`方法或直接通过`类名.class`的方式获取类的`Class`对象。
```java
Class<?> myClass = MyClass.class;
```
3. **获取可变参数方法的Method对象**：调用`findMethod()`方法获取目标方法，第二个参数传入可变参数对应的数组类型`Class`对象。假设`reflectUtil`是`org.springframework.util.ReflectionUtils`，代码如下：
```java
import org.springframework.util.ReflectionUtils;
import java.lang.reflect.Method;

Method method = ReflectionUtils.findMethod(myClass, "varArgsMethod", String[].class);
```
4. **调用方法**：获取到`Method`对象后，若方法不是静态方法，需先创建类的实例，然后使用`Method.invoke()`方法调用该方法。传递参数时，将实际参数包装成对应类型的数组，再将数组作为一个参数传入`invoke`方法，且如果是引用类型参数，通常还需要将数组强转为`Object`类型。
```java
Object instance = myClass.getDeclaredConstructor().newInstance();
String[] params = {"Hello", "World", "from", "Reflection"};
method.invoke(instance, (Object) params);
```

### 如何实现一个基于LRU淘汰策略的队列？



### 